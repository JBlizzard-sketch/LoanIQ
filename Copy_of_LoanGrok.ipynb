{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JBlizzard-sketch/LoanIQ/blob/main/Copy_of_LoanGrok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9P_0aCfQnCM",
        "outputId": "3f7d79fd-11a4-4009-9821-816d22c7ad40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting setup at Wed Sep  3 02:01:32 PM UTC 2025\n",
            "✅ Folders created\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%bash\n",
        "set -euo pipefail\n",
        "echo \"🚀 Starting setup at $(date)\"\n",
        "\n",
        "# ---------- Folder structure ----------\n",
        "mkdir -p /content/LoanIQ/modules/synth \\\n",
        "         /content/LoanIQ/modules/ml \\\n",
        "         /content/LoanIQ/modules/app \\\n",
        "         /content/LoanIQ/modules/auth \\\n",
        "         /content/LoanIQ/modules/pipeline \\\n",
        "         /content/LoanIQ/modules/schema \\\n",
        "         /content/LoanIQ/data/uploads \\\n",
        "         /content/LoanIQ/data/synthetic \\\n",
        "         /content/LoanIQ/exports/reports \\\n",
        "         /content/LoanIQ/exports/logs\n",
        "\n",
        "echo \"✅ Folders created\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== CELL 1 — ENVIRONMENT & SETUP ==========================\n",
        "\n",
        "# ---------- Install dependencies ----------\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        print(f\"Installing {package} ...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package])\n",
        "\n",
        "# Packages (skip if installed)\n",
        "packages = [\n",
        "    \"streamlit\", \"pandas\", \"numpy\", \"scikit-learn\", \"xgboost\", \"imbalanced-learn\",\n",
        "    \"shap\", \"faker\", \"pyngrok\", \"matplotlib\", \"seaborn\", \"plotly\", \"reportlab\", \"python-dotenv\"\n",
        "]\n",
        "\n",
        "for pkg in packages:\n",
        "    install(pkg)\n",
        "\n",
        "print(\"✅ Dependencies installed / confirmed.\")\n",
        "\n",
        "# ---------- Folder structure ----------\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"/content/LoanIQ\").resolve()\n",
        "MODULES = ROOT / \"modules\"\n",
        "DATA = ROOT / \"data\"\n",
        "EXPORTS = ROOT / \"exports\"\n",
        "\n",
        "FOLDERS = [\n",
        "    MODULES / \"synth\",\n",
        "    MODULES / \"ml\",\n",
        "    MODULES / \"app\",\n",
        "    MODULES / \"auth\",\n",
        "    MODULES / \"pipeline\",\n",
        "    MODULES / \"schema\",\n",
        "    DATA / \"uploads\",\n",
        "    DATA / \"synthetic\",\n",
        "    EXPORTS / \"reports\",\n",
        "    EXPORTS / \"logs\"\n",
        "]\n",
        "\n",
        "for folder in FOLDERS:\n",
        "    folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create empty __init__.py for modules\n",
        "import os\n",
        "for subfolder in MODULES.glob(\"**/\"):\n",
        "    init_file = subfolder / \"__init__.py\"\n",
        "    if not init_file.exists():\n",
        "        init_file.touch()\n",
        "\n",
        "print(\"✅ Folder structureready, __init__.py created.\")\n",
        "\n",
        "# ---------- Colab-safe import paths ----------\n",
        "import sys\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "print(\"✅ sys.path updated.\")\n",
        "\n",
        "# ---------- Hardcoded secrets ----------\n",
        "ADMIN_USERNAME = \"Admin\"\n",
        "ADMIN_PASSWORD = \"Shady868\"\n",
        "NGROK_AUTHTOKEN = \"31rYvgklL0EdX9bGLvTXc313efE_2GyDFGPUNAyFgB83bikTF\"\n",
        "\n",
        "print(f\"✅ Hardcoded admin credentials and ngrok token set.\")\n",
        "\n",
        "# ---------- Smoke test imports ----------\n",
        "try:\n",
        "    import modules.app.client_panel as client_panel\n",
        "    import modules.app.app as app_module\n",
        "    import modules.ml.engine as ml_engine\n",
        "    import modules.pipeline.pipeline as pipeline\n",
        "    import modules.schema.schema as schema\n",
        "    import modules.auth.auth as auth\n",
        "    import modules.synth.generator as generator\n",
        "    print(\"✅ Smoke test: All modules imported successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Import failed:\", e)\n",
        "\n",
        "print(\"\\n✅ CELL 1 complete — Environment setup ready for Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPQXtcPN0Y6K",
        "outputId": "8e1c1703-969a-42f9-9a83-c169b5defbfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing scikit-learn ...\n",
            "Installing imbalanced-learn ...\n",
            "Installing python-dotenv ...\n",
            "✅ Dependencies installed / confirmed.\n",
            "✅ Folder structureready, __init__.py created.\n",
            "✅ sys.path updated.\n",
            "✅ Hardcoded admin credentials and ngrok token set.\n",
            "❌ Import failed: cannot import name 'authenticate' from 'modules.auth' (/content/LoanIQ/modules/auth/__init__.py)\n",
            "\n",
            "✅ CELL 1 complete — Environment setup ready for Colab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQEXWDf_EXeJ",
        "outputId": "24e9317d-6bf3-4363-c1d4-8dd651e94fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/LoanIQ/modules/auth.py\n",
            "Wrote: /content/LoanIQ/modules/synth/generator.py\n",
            "Wrote: /content/LoanIQ/modules/schema.py\n",
            "Wrote: /content/LoanIQ/modules/pipeline.py\n",
            "✅ modules.auth\n",
            "✅ modules.synth.generator\n",
            "✅ modules.schema\n",
            "✅ modules.pipeline\n",
            "\n",
            "✅ Core modules ready.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import textwrap, os\n",
        "\n",
        "ROOT = Path(\"/content/LoanIQ\").resolve()\n",
        "MODULES = ROOT / \"modules\"\n",
        "SYNTH_DIR = MODULES / \"synth\"\n",
        "for d in [MODULES, SYNTH_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def write_module(path: Path, content: str):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(content, encoding='utf-8')\n",
        "    print(f\"Wrote: {path}\")\n",
        "\n",
        "# auth.py\n",
        "auth_py = textwrap.dedent(\"\"\"\\\n",
        "import os, sqlite3, hashlib\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(__file__).resolve().parents[1]\n",
        "DB_DIR = ROOT / \"data\"\n",
        "DB_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DB_PATH = DB_DIR / \"users.db\"\n",
        "\n",
        "def _conn():\n",
        "    return sqlite3.connect(str(DB_PATH), check_same_thread=False)\n",
        "\n",
        "def _hash(pw: str) -> str:\n",
        "    return hashlib.sha256(pw.encode('utf-8')).hexdigest()\n",
        "\n",
        "def init_db():\n",
        "    conn = _conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY AUTOINCREMENT, username TEXT UNIQUE, password_hash TEXT, role TEXT DEFAULT 'user')\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def add_user(username: str, password: str, role: str = 'user', overwrite: bool = False):\n",
        "    conn = _conn(); cur = conn.cursor()\n",
        "    ph = _hash(password)\n",
        "    if overwrite:\n",
        "        cur.execute('DELETE FROM users WHERE username=?', (username,))\n",
        "    try:\n",
        "        cur.execute('INSERT INTO users (username, password_hash, role) VALUES (?,?,?)', (username, ph, role))\n",
        "        conn.commit()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        if 'UNIQUE constraint' in str(e) and overwrite:\n",
        "            cur.execute('UPDATE users SET password_hash=?, role=? WHERE username=?', (ph,role,username))\n",
        "            conn.commit()\n",
        "            return True\n",
        "        return False\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "def authenticate(username: str, password: str):\n",
        "    conn = _conn(); cur = conn.cursor()\n",
        "    cur.execute('SELECT password_hash, role FROM users WHERE username=?', (username,))\n",
        "    row = cur.fetchone()\n",
        "    conn.close()\n",
        "    if not row:\n",
        "        return False, 'not_found'\n",
        "    ph, role = row\n",
        "    if ph == _hash(password):\n",
        "        return True, role\n",
        "    return False, 'bad_password'\n",
        "\n",
        "def list_users():\n",
        "    conn = _conn(); cur = conn.cursor()\n",
        "    cur.execute('SELECT id, username, role FROM users')\n",
        "    rows = cur.fetchall(); conn.close()\n",
        "    return rows\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_db()\n",
        "    print('Auth DB ready at', DB_PATH)\n",
        "\"\"\")\n",
        "write_module(MODULES / \"auth.py\", auth_py)\n",
        "\n",
        "# synth/generator.py with enhanced faker\n",
        "synth_py = textwrap.dedent(\"\"\"\\\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "fake = Faker(); Faker.seed(42); random.seed(42); np.random.seed(42)\n",
        "\n",
        "MALE_NAMES = ['Joseph', 'John', 'David', 'James', 'William', 'Peter', 'Brian', 'Jackson', 'Kamau', 'Mwangi', 'Onyango', 'Kipchoge', 'Juma', 'Baraka', 'Henry', 'Aiden', 'Kyalo', 'Muthui', 'Matu', 'Badru', 'Azizi']\n",
        "FEMALE_NAMES = ['Sarah', 'Naomi', 'Irene', 'Mary', 'Anne', 'Elizabeth', 'Mercy', 'Faith', 'Caro', 'Lilian', 'Njeri', 'Wanjiku', 'Atieno', 'Jepkosgei', 'Zawadi', 'Amani', 'Ayana', 'Mumbi', 'Makena', 'Kioni', 'Kainda']\n",
        "LAST_NAMES = ['Njuguna', 'Onyango', 'Aduda', 'Mwayi', 'Nthambi', 'Kyeli', 'Egadwa', 'Simiyu', 'Mwangi', 'Kamau', 'Otieno', 'Cheruiyot', 'Juma', 'Baraka']\n",
        "\n",
        "BRANCHES = ['Mpeketoni', 'Ugunja', 'Nakuru', 'Molo', 'Changamwe', 'Kanyangi', 'Mbale', \"Moi's Bridge\", 'Ruiru', 'Thika', 'Kikuyu', 'Ngong', 'Mavoko', 'Westlands', 'Dagoretti', 'Kilimani', 'Kawangware', 'Machakos', 'Kitui', 'Meru', 'Embu', 'Kangundo', 'Maua', 'Garissa', 'Mandera', 'Isiolo', 'Marsabit', 'Mombasa', 'Malindi', 'Lamu', 'Watamu', 'Diani', 'Kilifi', 'Nyali', 'Bamburi', 'Mtwapa', 'Nyeri', 'Kiambu', 'Kerugoya', 'Nyahururu', \"Murang'a\", 'Karuri', 'Ol Kalou', 'Nanyuki', 'Rumuruti', 'Eldoret', 'Kisumu', 'Kakamega', 'Kitale']\n",
        "\n",
        "PRODUCTS = ['INUKA 4 WEEKS', 'KUZA 4 WEEKS', 'KUZA 5 WEEKS', 'INUKA 5 WEEKS', 'FADHILI WEEKS']\n",
        "\n",
        "STATUSES = ['Active', 'Pending Branch Approval', 'Rejected']\n",
        "\n",
        "def infer_age_from_id(id_num):\n",
        "    prefix = int(str(id_num)[:2]) if len(str(id_num)) >= 2 else random.randint(1, 35)\n",
        "    if 1 <= prefix <= 10: return random.randint(60, 80)\n",
        "    elif 11 <= prefix <= 20: return random.randint(50, 60)\n",
        "    elif 21 <= prefix <= 25: return random.randint(40, 50)\n",
        "    elif 26 <= prefix <= 31: return random.randint(30, 40)\n",
        "    elif 32 <= prefix <= 34: return random.randint(27, 30)\n",
        "    else: return random.randint(18, 26)\n",
        "\n",
        "def _skewed_loan_amount(min_amt=4000, max_amt=15000, skew=1.8):\n",
        "    r = random.random() ** skew\n",
        "    return int(min_amt + (max_amt - min_amt) * r)\n",
        "\n",
        "def generate_national_id():\n",
        "    return random.randint(1000000, 39999999)\n",
        "\n",
        "def generate_phone():\n",
        "    return \"+2547\" + str(random.randint(1000000, 9999999))\n",
        "\n",
        "def generate_sample(n=1000, branches=None, fraud_pct=0.02, default_rate=0.08, multi_loan_frac=0.12, seed=None):\n",
        "    if seed is not None:\n",
        "        random.seed(seed); np.random.seed(seed)\n",
        "    branches = branches or BRANCHES\n",
        "    rows = []\n",
        "    client_counter = 0\n",
        "    for i in range(n):\n",
        "        is_female = random.choices([True, False], weights=[70, 30])[0]\n",
        "        first = random.choice(FEMALE_NAMES if is_female else MALE_NAMES)\n",
        "        last = random.choice(LAST_NAMES)\n",
        "        name = f\"{first} {last}\"\n",
        "        nid = generate_national_id()\n",
        "        age = infer_age_from_id(nid)\n",
        "        gender = 'female' if is_female else 'male'\n",
        "        phone = generate_phone()\n",
        "        branch = random.choice(branches)\n",
        "        product = random.choice(PRODUCTS)\n",
        "        income = random.randint(4000, 8000)\n",
        "        occupation = random.choices(['Small Business', 'Salaried'], weights=[80, 20])[0]\n",
        "        amount = _skewed_loan_amount()\n",
        "        created = datetime.utcnow() - timedelta(days=random.randint(0, 30))\n",
        "        ref = created.strftime('%y%m%d') + str(random.randint(10000, 99999))\n",
        "        loan_type = 'Normal'\n",
        "        is_fraud = random.random() < fraud_pct\n",
        "        prob_default = default_rate + (0.02 if amount > 40000 else -0.005) + (0.01 if income < 5000 else -0.005)\n",
        "        status = random.choices(STATUSES, weights=[50, 40, 10])[0]\n",
        "        health = random.choices(['Performing', 'Non-Performing'], weights=[90, 10])[0]\n",
        "        collateral = 'None'\n",
        "        if is_fraud:\n",
        "            if random.random() < 0.3 and rows:\n",
        "                r = random.choice(rows)\n",
        "                nid = r['national_id']\n",
        "                phone = r['phone']\n",
        "            else:\n",
        "                amount = amount * random.randint(2,4)\n",
        "                income = int(income * random.uniform(0.2, 0.6))\n",
        "            status = random.choices(STATUSES, weights=[60, 20, 20])[0]\n",
        "        rows.append({\n",
        "            'record_id': f\"R{i:08d}\",\n",
        "            'client_id': client_counter,\n",
        "            'name': name,\n",
        "            'national_id': nid,\n",
        "            'phone': phone,\n",
        "            'branch': branch,\n",
        "            'product': product,\n",
        "            'income': income,\n",
        "            'loan_amount': amount,\n",
        "            'loan_status': status,\n",
        "            'loan_health': health,\n",
        "            'created_date': created.strftime('%Y-%m-%d'),\n",
        "            'gender': gender,\n",
        "            'age': age,\n",
        "            'occupation': occupation,\n",
        "            'collateral': collateral,\n",
        "            'ref_number': ref,\n",
        "            'loan_type': loan_type,\n",
        "            'simulated_fraud': int(is_fraud)\n",
        "        })\n",
        "        if random.random() < multi_loan_frac:\n",
        "            extra_amount = int(amount * random.uniform(0.3, 1.2))\n",
        "            created2 = created - timedelta(days=random.randint(30, 90))\n",
        "            rows.append({\n",
        "                'record_id': f\"R{i:08d}_2\",\n",
        "                'client_id': client_counter,\n",
        "                'name': name,\n",
        "                'national_id': nid,\n",
        "                'phone': phone,\n",
        "                'branch': branch,\n",
        "                'product': random.choice(PRODUCTS),\n",
        "                'income': income,\n",
        "                'loan_amount': extra_amount,\n",
        "                'loan_status': 'performing',\n",
        "                'loan_health': health,\n",
        "                'created_date': created2.strftime('%Y-%m-%d'),\n",
        "                'gender': gender,\n",
        "                'age': age,\n",
        "                'occupation': occupation,\n",
        "                'collateral': collateral,\n",
        "                'ref_number': created2.strftime('%y%m%d') + str(random.randint(10000, 99999)),\n",
        "                'loan_type': loan_type,\n",
        "                'simulated_fraud': 0\n",
        "            })\n",
        "        client_counter += 1\n",
        "    df = pd.DataFrame(rows)\n",
        "    df['loan_amount'] = pd.to_numeric(df['loan_amount'], errors='coerce').fillna(0).astype(int)\n",
        "    df['income'] = pd.to_numeric(df['income'], errors='coerce').fillna(0).astype(int)\n",
        "    df['simulated_fraud'] = df['simulated_fraud'].fillna(0).astype(int)\n",
        "    return df\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(generate_sample(10).head().to_dict(orient='records'))\n",
        "\"\"\")\n",
        "write_module(SYNTH_DIR / \"generator.py\", synth_py)\n",
        "\n",
        "# schema.py\n",
        "schema_py = textwrap.dedent(\"\"\"\\\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List\n",
        "\n",
        "EXPECTED_COLUMNS = ['record_id','client_id','name','national_id','phone','branch','product', 'income','loan_amount','loan_status','created_date','gender', 'age', 'occupation', 'collateral', 'ref_number', 'loan_type', 'loan_health']\n",
        "\n",
        "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df.columns = [c.strip().lower().replace(' ', '_') for c in df.columns]\n",
        "    return df\n",
        "\n",
        "def validate_columns(df: pd.DataFrame, expected: List[str]=None) -> List[str]:\n",
        "    expected = expected or EXPECTED_COLUMNS\n",
        "    cols = [c.strip().lower() for c in df.columns]\n",
        "    missing = [c for c in expected if c not in cols]\n",
        "    return missing\n",
        "\n",
        "def simple_preprocess(df: pd.DataFrame, target_col: str = 'loan_status'):\n",
        "    df = normalize_columns(df)\n",
        "    if 'loan_amount' in df.columns:\n",
        "        df['loan_amount'] = pd.to_numeric(df['loan_amount'].astype(str).str.replace('[^0-9.-]','',regex=True), errors='coerce').fillna(0)\n",
        "    if 'income' in df.columns:\n",
        "        df['income'] = pd.to_numeric(df['income'].astype(str).str.replace('[^0-9.-]','',regex=True), errors='coerce').fillna(0)\n",
        "    if target_col in df.columns:\n",
        "        df[target_col] = df[target_col].astype(str).str.lower().map(lambda x: 1 if 'default' in x else 0)\n",
        "    return df\n",
        "\"\"\")\n",
        "write_module(MODULES / \"schema.py\", schema_py)\n",
        "\n",
        "# pipeline.py\n",
        "pipeline_py = textwrap.dedent(\"\"\"\\\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df['loan_to_income'] = df.apply(lambda r: (r['loan_amount'] / (r['income'] + 1)) if r.get('income',0) is not None else 0, axis=1)\n",
        "    def bucket_amt(x):\n",
        "        if x <= 5000: return 'micro'\n",
        "        if x <= 20000: return 'small'\n",
        "        if x <= 50000: return 'medium'\n",
        "        return 'large'\n",
        "    df['loan_size_bucket'] = df['loan_amount'].apply(bucket_amt)\n",
        "    try:\n",
        "        df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')\n",
        "        df['days_since_loan'] = (pd.Timestamp.utcnow() - df['created_date']).dt.days.fillna(9999).astype(int)\n",
        "    except Exception:\n",
        "        df['days_since_loan'] = 9999\n",
        "    df['dup_nid'] = df.duplicated(subset=['national_id'], keep=False).astype(int)\n",
        "    df['extreme_lti'] = ((df['loan_to_income'] > 10) | (df['loan_amount'] > 200000)).astype(int)\n",
        "    df['fraud_score'] = df['simulated_fraud'].fillna(0) * 2 + df['dup_nid'] * 1 + df['extreme_lti'] * 2\n",
        "    df['risk_score'] = (df['fraud_score'] + (df['loan_to_income'] / (df['loan_to_income'].max() + 1))).fillna(0)\n",
        "    maxv = df['risk_score'].replace([np.inf, -np.inf], 0).max()\n",
        "    if pd.notna(maxv) and maxv > 0:\n",
        "        df['risk_score'] = df['risk_score'] / maxv\n",
        "    else:\n",
        "        df['risk_score'] = 0.0\n",
        "    return df\n",
        "\n",
        "def top_risky_branches(df: pd.DataFrame, top_n=5):\n",
        "    gv = df.groupby('branch').agg(avg_risk = ('risk_score', 'mean'), total_loans = ('record_id', 'count'), fraud_count = ('simulated_fraud', 'sum')).reset_index().sort_values('avg_risk', ascending=False)\n",
        "    return gv.head(top_n)\n",
        "\"\"\")\n",
        "write_module(MODULES / \"pipeline.py\", pipeline_py)\n",
        "\n",
        "# __init__.py\n",
        "for p in [MODULES, SYNTH_DIR]: (p / \"__init__.py\").write_text(\"# init\\n\")\n",
        "\n",
        "# Import checks\n",
        "import importlib, sys\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "failed = []\n",
        "for mod in (\"modules.auth\", \"modules.synth.generator\", \"modules.schema\", \"modules.pipeline\"):\n",
        "    try:\n",
        "        m = importlib.import_module(mod)\n",
        "        importlib.reload(m)\n",
        "        print(\"✅\", mod)\n",
        "    except Exception as e:\n",
        "        print(\"❌\", mod, \"->\", e)\n",
        "        failed.append(mod)\n",
        "if failed:\n",
        "    print(\"\\nSome imports failed.\")\n",
        "else:\n",
        "    print(\"\\n✅ Core modules ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T4YHhOpEjJX",
        "outputId": "109cbbad-cd75-47f3-a8a8-df228b10daf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/LoanIQ/modules/ml/engine.py\n",
            "ML engine smoke failed: module 'modules.schema' has no attribute 'simple_preprocess'\n",
            "\n",
            "✅ ML engine ready.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import textwrap, os\n",
        "\n",
        "ROOT = Path(\"/content/LoanIQ\").resolve()\n",
        "ML_DIR = ROOT / \"modules\" / \"ml\"\n",
        "MODELS_DIR = ROOT / \"models\"\n",
        "ML_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ml_engine_py = textwrap.dedent(\"\"\"\\\n",
        "import os, joblib, time, json, hashlib, datetime\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from modules import schema, pipeline\n",
        "\n",
        "BASE = Path(__file__).resolve().parents[1]\n",
        "MODELS_DIR = BASE / \"models\"\n",
        "\n",
        "def _hash_cfg(cfg: dict) -> str:\n",
        "    return hashlib.sha1(json.dumps(cfg, sort_keys=True).encode()).hexdigest()[:8]\n",
        "\n",
        "def prepare_dataset(df: pd.DataFrame, target_col=\"loan_status\"):\n",
        "    df = schema.simple_preprocess(df, target_col=target_col)\n",
        "    df = pipeline.add_features(df)\n",
        "    drop_cols = ['record_id','client_id','name','national_id','phone',target_col]\n",
        "    feature_cols = [c for c in df.columns if c not in drop_cols]\n",
        "    X = df[feature_cols].copy()\n",
        "    y = df[target_col]\n",
        "    for col in X.select_dtypes(include=['object']).columns:\n",
        "        X[col] = X[col].astype('category').cat.codes\n",
        "    for col in X.select_dtypes(include=['datetime64[ns]']).columns:\n",
        "        X[col] = X[col].view('int64') // 10**9\n",
        "    return X, y, feature_cols\n",
        "\n",
        "def train_model(df: pd.DataFrame, target_col=\"loan_status\", model_params=None, version_note=\"baseline\"):\n",
        "    X, y, feature_cols = prepare_dataset(df, target_col)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "    params = {\"n_estimators\": 120, \"max_depth\": 5, \"learning_rate\": 0.1, \"subsample\": 0.9, \"colsample_bytree\": 0.9, \"eval_metric\": \"logloss\", \"use_label_encoder\": False, \"tree_method\": \"hist\"}\n",
        "    if model_params:\n",
        "        params.update(model_params)\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    proba = model.predict_proba(X_test)[:,1]\n",
        "    auc = roc_auc_score(y_test, proba)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    report = classification_report(y_test, preds, output_dict=True)\n",
        "    version_id = f\"v{int(time.time())}_{_hash_cfg(params)}\"\n",
        "    artifact_dir = MODELS_DIR / version_id\n",
        "    artifact_dir.mkdir(parents=True, exist_ok=True)\n",
        "    joblib.dump({\"model\": model, \"features\": feature_cols, \"params\": params}, artifact_dir / \"model.joblib\")\n",
        "    (artifact_dir / \"metrics.json\").write_text(json.dumps({\"auc\": float(auc), \"f1\": float(f1), \"report\": report, \"version_note\": version_note, \"timestamp\": str(datetime.datetime.utcnow())}, indent=2))\n",
        "    return {\"version_id\": version_id, \"auc\": auc, \"f1\": f1, \"artifact\": str(artifact_dir)}\n",
        "\n",
        "def load_model(version_id: str):\n",
        "    artifact_dir = MODELS_DIR / version_id\n",
        "    obj = joblib.load(artifact_dir / \"model.joblib\")\n",
        "    return obj\n",
        "\n",
        "def list_models():\n",
        "    return sorted([d.name for d in MODELS_DIR.iterdir() if d.is_dir()])\n",
        "\n",
        "def predict(df: pd.DataFrame, version_id: str):\n",
        "    obj = load_model(version_id)\n",
        "    model, features = obj['model'], obj['features']\n",
        "    df_proc = pipeline.add_features(schema.simple_preprocess(df))\n",
        "    X = df_proc.reindex(columns=features, fill_value=0).copy()\n",
        "    for col in X.select_dtypes(include=['object']).columns:\n",
        "        X[col] = X[col].astype('category').cat.codes\n",
        "    for col in X.select_dtypes(include=['datetime64[ns]']).columns:\n",
        "        X[col] = X[col].view('int64') // 10**9\n",
        "    proba = model.predict_proba(X)[:,1]\n",
        "    preds = (proba > 0.5).astype(int)\n",
        "    return preds, proba\n",
        "\n",
        "def fraud_trigger(df: pd.DataFrame, risk_threshold=0.7):\n",
        "    df2 = pipeline.add_features(schema.simple_preprocess(df))\n",
        "    suspicious = df2[df2['risk_score'] > risk_threshold]\n",
        "    return suspicious\n",
        "\"\"\")\n",
        "write_module(ML_DIR / \"engine.py\", ml_engine_py)\n",
        "\n",
        "# __init__.py\n",
        "(ML_DIR / \"__init__.py\").write_text(\"# init\\n\")\n",
        "\n",
        "# Smoke test\n",
        "import importlib, sys\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "try:\n",
        "    import modules.ml.engine as engine\n",
        "    importlib.reload(engine)\n",
        "    from modules.synth import generator\n",
        "    df = generator.generate_sample(n=300, fraud_pct=0.05, default_rate=0.1, seed=123)\n",
        "    res = engine.train_model(df, version_note=\"smoke_test\")\n",
        "    print(\"Model trained:\", res)\n",
        "    print(\"Available models:\", engine.list_models())\n",
        "except Exception as e:\n",
        "    print(\"ML engine smoke failed:\", e)\n",
        "print(\"\\n✅ ML engine ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6C_A1zXtEus5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b21f298d-4033-450b-d8d7-f85ad04c8a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/LoanIQ/modules/admin_tools.py\n",
            "Admin tools smoke failed: cannot import name 'authenticate' from 'modules.auth' (/content/LoanIQ/modules/auth/__init__.py)\n",
            "\n",
            "✅ Admin tools ready.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import textwrap, os\n",
        "\n",
        "ROOT = Path(\"/content/LoanIQ\").resolve()\n",
        "ADMIN_TOOLS = ROOT / \"modules\" / \"admin_tools.py\"\n",
        "\n",
        "admin_tools_py = textwrap.dedent(\"\"\"\\\n",
        "import os, time, json, traceback\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from modules.synth.generator import generate_sample\n",
        "from modules.ml import engine\n",
        "from modules import schema, pipeline\n",
        "from modules.auth import authenticate, init_db, add_user\n",
        "\n",
        "ROOT = Path(__file__).resolve().parents[1]\n",
        "MODELS_DIR = ROOT / \"models\"\n",
        "SCHEMA_BACKUPS = ROOT / \"schema_backups\"\n",
        "SCHEMA_BACKUPS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def generate_synthetic(records: int = 1000, branches: List[str] = None, fraud_pct: float = 0.02, default_rate: float = 0.08, seed: int = None) -> dict:\n",
        "    df = generate_sample(n=records, branches=branches, fraud_pct=fraud_pct, default_rate=default_rate, seed=seed)\n",
        "    try:\n",
        "        df_proc = pipeline.add_features(schema.simple_preprocess(df))\n",
        "        summary = {'records': len(df_proc), 'branches': sorted(df_proc['branch'].unique().tolist()), 'simulated_fraud': int(df_proc['simulated_fraud'].sum()), 'avg_loan': float(df_proc['loan_amount'].mean()), 'median_income': float(df_proc['income'].median())}\n",
        "    except Exception:\n",
        "        summary = {'records': len(df), 'error': 'feature extraction failed'}\n",
        "    return {'df': df, 'summary': summary}\n",
        "\n",
        "def retrain_model(df, target_col='loan_status', model_params=None, version_note='admin_retrain'):\n",
        "    try:\n",
        "        res = engine.train_model(df, target_col=target_col, model_params=model_params, version_note=version_note)\n",
        "        return {'ok': True, 'result': res}\n",
        "    except Exception as e:\n",
        "        return {'ok': False, 'error': str(e), 'trace': traceback.format_exc()}\n",
        "\n",
        "def fraud_stress_test(base_records=500, branches=None, fraud_steps=[0.01,0.05,0.1,0.2], default_rate=0.08, detection_threshold=0.7):\n",
        "    results = []\n",
        "    for p in fraud_steps:\n",
        "        df = generate_sample(n=base_records, branches=branches, fraud_pct=p, default_rate=default_rate, seed=int(time.time())%9999)\n",
        "        injected = int(df['simulated_fraud'].sum())\n",
        "        suspicious = engine.fraud_trigger(df, risk_threshold=detection_threshold)\n",
        "        detected = len(suspicious)\n",
        "        detection_rate = (detected / injected) if injected > 0 else None\n",
        "        results.append({'fraud_pct': p, 'injected': int(injected), 'detected': int(detected), 'detection_rate': detection_rate})\n",
        "    return results\n",
        "\n",
        "def inject_schema(new_expected_columns: List[str], tag: str = None):\n",
        "    tag = tag or time.strftime('%Y%m%d_%H%M%S')\n",
        "    path = SCHEMA_BACKUPS / f'schema_{tag}.json'\n",
        "    metadata = {'expected_columns': new_expected_columns, 'tag': tag, 'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ')}\n",
        "    path.write_text(json.dumps(metadata, indent=2))\n",
        "    return {'ok': True, 'backup': str(path), 'metadata': metadata}\n",
        "\n",
        "def impersonate_user(username='demo_user'):\n",
        "    token = {'impersonated_user': username, 'issued_at': time.time(), 'expires_in': 3600, 'token': f\"impersonate_{username}_{int(time.time())}\"}\n",
        "    return token\n",
        "\n",
        "def ensure_admin():\n",
        "    init_db()\n",
        "    add_user('Admin', 'Shady868', role='admin', overwrite=True)\n",
        "    return True\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ensure_admin()\n",
        "    print('Generating 200 sample records...')\n",
        "    out = generate_synthetic(records=200, fraud_pct=0.05)\n",
        "    print('Summary:', out['summary'])\n",
        "    r = retrain_model(out['df'], version_note='cli_demo_retrain')\n",
        "    print('Retrain ->', r)\n",
        "    s = fraud_stress_test(base_records=300, fraud_steps=[0.02,0.05,0.1], detection_threshold=0.6)\n",
        "    print('Stress test ->', s)\n",
        "\"\"\")\n",
        "write_module(ADMIN_TOOLS, admin_tools_py)\n",
        "\n",
        "# Smoke test\n",
        "import importlib, sys\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "try:\n",
        "    import modules.admin_tools as admin_tools\n",
        "    importlib.reload(admin_tools)\n",
        "    admin_tools.ensure_admin()\n",
        "    demo = admin_tools.generate_synthetic(records=200, fraud_pct=0.04, default_rate=0.12)\n",
        "    print(\"Synthetic summary:\", demo['summary'])\n",
        "    retrain_res = admin_tools.retrain_model(demo['df'], version_note=\"admin_cell4_demo\")\n",
        "    print(\"Retrain result:\", retrain_res)\n",
        "    stress = admin_tools.fraud_stress_test(base_records=300, fraud_steps=[0.02, 0.05, 0.1], detection_threshold=0.6)\n",
        "    print(\"Stress test:\", stress)\n",
        "except Exception as e:\n",
        "    print(\"Admin tools smoke failed:\", e)\n",
        "print(\"\\n✅ Admin tools ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aVsiMt7E6eE",
        "outputId": "8aedc601-153d-4602-d955-e5b348ddab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Client panel imported.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import textwrap\n",
        "\n",
        "ROOT = Path(\"/content/LoanIQ\").resolve()\n",
        "APP_DIR = ROOT / \"modules\" / \"app\"\n",
        "CLIENT_PANEL = APP_DIR / \"client_panel.py\"\n",
        "APP_PY = APP_DIR / \"app.py\"\n",
        "APP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "client_panel_py = textwrap.dedent(\"\"\"\\\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import plotly.express as px\n",
        "import shap\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from modules.synth import generator\n",
        "from modules import schema, pipeline\n",
        "from modules.ml import engine\n",
        "\n",
        "def app():\n",
        "    st.title(\"📊 LoanIQ — Client Dashboard\")\n",
        "    st.markdown(\"Upload your loan book or generate a synthetic dataset to explore insights.\")\n",
        "\n",
        "    option = st.radio(\"Choose dataset source:\", [\"Upload CSV/Excel\", \"Simulate dataset\"], horizontal=True)\n",
        "\n",
        "    df = None\n",
        "    if option == \"Upload CSV/Excel\":\n",
        "        file = st.file_uploader(\"Upload loan dataset (CSV/XLSX)\", type=[\"csv\",\"xlsx\"])\n",
        "        if file is not None:\n",
        "            try:\n",
        "                if file.name.endswith('.xlsx'):\n",
        "                    df = pd.read_excel(file)\n",
        "                else:\n",
        "                    df = pd.read_csv(file)\n",
        "                st.success(f\"Uploaded {len(df)} records.\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"Failed to read file: {e}\")\n",
        "    else:\n",
        "        st.subheader(\"Simulate dataset\")\n",
        "        n = st.slider(\"Number of records\", 100, 10000, 500, step=100)\n",
        "        fraud_pct = st.slider(\"Fraud percentage\", 0.0, 0.5, 0.05, step=0.01)\n",
        "        default_rate = st.slider(\"Default rate\", 0.0, 0.5, 0.08, step=0.01)\n",
        "        branches = st.multiselect(\"Branches\", generator.BRANCHES, default=generator.BRANCHES[:3])\n",
        "        if st.button(\"Generate dataset\"):\n",
        "            df = generator.generate_sample(n=n, branches=branches, fraud_pct=fraud_pct, default_rate=default_rate, seed=42)\n",
        "            st.success(f\"Generated {len(df)} synthetic records.\")\n",
        "\n",
        "    if df is None or df.empty:\n",
        "        st.info(\"Please upload or generate a dataset to continue.\")\n",
        "        return\n",
        "\n",
        "    df_proc = pipeline.add_features(schema.simple_preprocess(df))\n",
        "    st.subheader(\"Portfolio Overview\")\n",
        "    c1, c2, c3, c4 = st.columns(4)\n",
        "    c1.metric(\"Total Loans\", f\"{len(df_proc)}\")\n",
        "    c2.metric(\"Fraud Flags\", int(df_proc['simulated_fraud'].sum()))\n",
        "    c3.metric(\"Avg Risk Score\", f\"{df_proc['risk_score'].mean():.2f}\")\n",
        "    c4.metric(\"Total Loan Amount (KES)\", f\"{df_proc['loan_amount'].sum():,.0f}\")\n",
        "\n",
        "    # Per-Client Lookup\n",
        "    st.subheader(\"🔍 Per-Client Lookup\")\n",
        "    with st.form(\"lookup_form\"):\n",
        "        client_id = st.text_input(\"National ID or Phone\")\n",
        "        if st.form_submit_button(\"Search Client\"):\n",
        "            client_df = df_proc[(df_proc['national_id'] == client_id) | (df_proc['phone'] == client_id)]\n",
        "            if client_df.empty:\n",
        "                st.warning(\"No client found.\")\n",
        "            else:\n",
        "                st.dataframe(client_df[['record_id', 'loan_amount', 'loan_status', 'risk_score']])\n",
        "                st.metric(\"Total Loans for Client\", len(client_df))\n",
        "                st.metric(\"Avg Risk Score\", client_df['risk_score'].mean())\n",
        "                st.plotly_chart(px.timeline(client_df, x_start='created_date', x_end='created_date', y='loan_amount', title=\"Loan History Timeline\"))\n",
        "\n",
        "    # Risk Analysis\n",
        "    st.subheader(\"⚠️ Risk Analysis\")\n",
        "    risky = pipeline.top_risky_branches(df_proc, top_n=10)\n",
        "    st.dataframe(risky)\n",
        "    st.plotly_chart(px.bar(risky, x='branch', y='avg_risk', title=\"Top Risky Branches\"))\n",
        "\n",
        "    # Filters\n",
        "    branch_filter = st.selectbox(\"Filter by Branch\", ['All'] + df_proc['branch'].unique().tolist())\n",
        "    risk_filter = st.slider(\"Min Risk Score\", 0.0, 1.0, 0.0)\n",
        "    filtered_df = df_proc[df_proc['risk_score'] >= risk_filter]\n",
        "    if branch_filter != 'All':\n",
        "        filtered_df = filtered_df[filtered_df['branch'] == branch_filter]\n",
        "    st.dataframe(filtered_df.head(50))\n",
        "\n",
        "    # Rich Visuals\n",
        "    st.plotly_chart(px.pie(filtered_df, names='loan_status', title=\"Loan Status Breakdown\"))\n",
        "    st.plotly_chart(px.density_heatmap(filtered_df, x='branch', y='risk_score', title=\"Risk Heatmap by Branch\"))\n",
        "    st.plotly_chart(px.scatter(filtered_df, x='loan_amount', y='risk_score', color='branch', title=\"Loan Amount vs Risk Score\"))\n",
        "    st.plotly_chart(px.box(filtered_df, x='loan_size_bucket', y='risk_score', title=\"Risk by Loan Size Bucket\"))\n",
        "\n",
        "    # ML Predictions & Anomalies\n",
        "    st.subheader(\"📈 ML Predictions & Anomalies\")\n",
        "    versions = engine.list_models()\n",
        "    if not versions:\n",
        "        st.warning(\"No models trained yet. Ask Admin to train a baseline model.\")\n",
        "    else:\n",
        "        selected = st.selectbox(\"Select model version\", versions, index=len(versions)-1)\n",
        "        if st.button(\"Run Predictions\"):\n",
        "            X, y, features = engine.prepare_dataset(df_proc)\n",
        "            preds, proba = engine.predict(df_proc, version_id=selected)\n",
        "            df_proc['pred_default'] = preds\n",
        "            df_proc['prob_default'] = proba\n",
        "            st.write(f\"Predicted default rate: {df_proc['pred_default'].mean()*100:.2f}%\")\n",
        "            st.plotly_chart(px.histogram(df_proc, x='prob_default', color='pred_default', title=\"Default Probability Distribution\"))\n",
        "            # SHAP\n",
        "            obj = engine.load_model(selected)\n",
        "            model = obj['model']\n",
        "            explainer = shap.Explainer(model, X)\n",
        "            shap_values = explainer(X)\n",
        "            st.pyplot(shap.summary_plot(shap_values, X, plot_type=\"bar\", show=False))\n",
        "            # Anomaly Detection\n",
        "            iso = IsolationForest().fit(X)\n",
        "            anomalies = iso.predict(X)\n",
        "            anomaly_df = df_proc[anomalies == -1]\n",
        "            st.subheader(\"Potential Anomalies\")\n",
        "            st.dataframe(anomaly_df[['national_id', 'loan_amount', 'prob_default']])\n",
        "            st.metric(\"Anomalous Loans\", len(anomaly_df))\n",
        "            st.plotly_chart(px.scatter(anomaly_df, x='loan_amount', y='prob_default', title=\"Anomalies Scatter\"))\n",
        "\n",
        "    # What-if Analysis\n",
        "    st.subheader(\"🔮 What-if Analysis\")\n",
        "    with st.form(\"whatif_form\"):\n",
        "        loan_adj = st.slider(\"Loan size adjustment (%)\", -50, 50, 0)\n",
        "        income_adj = st.slider(\"Income adjustment (%)\", -50, 50, 0)\n",
        "        fraud_adj = st.slider(\"Fraud multiplier\", 0.5, 2.0, 1.0, step=0.1)\n",
        "        if st.form_submit_button(\"Run What-if\"):\n",
        "            df_whatif = df_proc.copy()\n",
        "            df_whatif['loan_amount'] = df_whatif['loan_amount'] * (1 + loan_adj/100)\n",
        "            df_whatif['income'] = df_whatif['income'] * (1 + income_adj/100)\n",
        "            df_whatif['simulated_fraud'] = df_whatif['simulated_fraud'] * fraud_adj\n",
        "            df_whatif = pipeline.add_features(df_whatif)\n",
        "            st.metric(\"Adjusted Avg Risk Score\", round(df_whatif['risk_score'].mean(),3))\n",
        "            st.plotly_chart(px.box(pd.DataFrame({'Original': df_proc['risk_score'], 'Adjusted': df_whatif['risk_score']}), title=\"Risk Comparison\"))\n",
        "\n",
        "    # Export\n",
        "    st.subheader(\"⬇️ Export Data\")\n",
        "    export_type = st.selectbox(\"Export Type\", [\"Full Dataset\", \"High-Risk Loans\", \"Client Lookup\", \"What-if Results\"])\n",
        "    export_df = df_proc if export_type == \"Full Dataset\" else df_proc[df_proc['risk_score'] > 0.7] if export_type == \"High-Risk Loans\" else client_df if 'client_df' in locals() else df_proc if export_type == \"Client Lookup\" else df_whatif if 'df_whatif' in locals() else df_proc\n",
        "    buffer = BytesIO()\n",
        "    export_df.to_csv(buffer, index=False)\n",
        "    st.download_button(\"Download CSV\", data=buffer.getvalue(), file_name=f\"{export_type.lower().replace(' ','_')}.csv\", mime=\"text/csv\")\n",
        "\n",
        "    st.success(\"Client dashboard ready.\")\n",
        "\"\"\")\n",
        "CLIENT_PANEL.write_text(client_panel_py, encoding=\"utf-8\")\n",
        "\n",
        "# main app.py with admin panel UI\n",
        "app_py = textwrap.dedent(\"\"\"\\\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import json\n",
        "from modules import auth, admin_tools, schema, pipeline\n",
        "import modules.app.client_panel as client_panel\n",
        "from modules.ml import engine\n",
        "from modules.synth import generator\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "\n",
        "ROOT = Path(\"/content/LoanIQ\").resolve()\n",
        "SCHEMA_BACKUPS = ROOT / \"schema_backups\"\n",
        "\n",
        "st.set_page_config(page_title=\"LoanIQ\", layout=\"wide\")\n",
        "auth.init_db()\n",
        "admin_tools.ensure_admin()\n",
        "\n",
        "if \"user\" not in st.session_state:\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.subheader(\"Login\")\n",
        "        username = st.text_input(\"Username\")\n",
        "        password = st.text_input(\"Password\", type=\"password\")\n",
        "        if st.button(\"Login\"):\n",
        "            ok, role = auth.authenticate(username, password)\n",
        "            if ok:\n",
        "                st.session_state['user'] = username\n",
        "                st.session_state['role'] = role\n",
        "                st.success(f\"Logged in as {username} ({role})\")\n",
        "            else:\n",
        "                st.error(\"Invalid credentials\")\n",
        "    with col2:\n",
        "        st.subheader(\"Register (user)\")\n",
        "        r_user = st.text_input(\"New username\")\n",
        "        r_pass = st.text_input(\"New password\", type=\"password\")\n",
        "        if st.button(\"Register\"):\n",
        "            auth.add_user(r_user, r_pass, role=\"user\")\n",
        "            st.success(\"User registered.\")\n",
        "    st.stop()\n",
        "\n",
        "menu_options = [\"Client Dashboard\"]\n",
        "if st.session_state[\"role\"] == \"admin\":\n",
        "    menu_options.append(\"Admin Sandbox\")\n",
        "menu = st.sidebar.selectbox(\"Menu\", menu_options)\n",
        "\n",
        "if menu == \"Client Dashboard\":\n",
        "    client_panel.app()\n",
        "elif menu == \"Admin Sandbox\":\n",
        "    st.title(\"LoanIQ — Admin Sandbox\")\n",
        "    st.info(\"Logged in as Admin\")\n",
        "\n",
        "    st.subheader(\"Admin Overview\")\n",
        "    c1, c2, c3 = st.columns(3)\n",
        "    c1.metric(\"Total Users\", len(auth.list_users()))\n",
        "    c2.metric(\"Models Trained\", len(engine.list_models()))\n",
        "    c3.metric(\"Schema Backups\", len(list(SCHEMA_BACKUPS.glob(\"*.json\"))))\n",
        "\n",
        "    with st.expander(\"Generate Synthetic Dataset\"):\n",
        "        with st.form(\"synthetic_form\"):\n",
        "            records = st.slider(\"Number of Records\", 100, 5000, 1000, step=100)\n",
        "            branches = st.multiselect(\"Branches\", generator.BRANCHES, default=generator.BRANCHES[:3])\n",
        "            fraud_pct = st.slider(\"Fraud Percentage\", 0.0, 0.3, 0.02, step=0.01)\n",
        "            default_rate = st.slider(\"Default Rate\", 0.0, 0.3, 0.08, step=0.01)\n",
        "            seed = st.number_input(\"Seed (optional)\", min_value=0, value=None, step=1)\n",
        "            if st.form_submit_button(\"Generate\"):\n",
        "                with st.spinner(\"Generating...\"):\n",
        "                    result = admin_tools.generate_synthetic(records, branches, fraud_pct, default_rate, seed)\n",
        "                    st.session_state[\"synthetic_df\"] = result[\"df\"]\n",
        "                st.json(result[\"summary\"])\n",
        "                st.dataframe(result[\"df\"].head(10))\n",
        "                st.download_button(\"Download Synthetic CSV\", result[\"df\"].to_csv(index=False), \"synthetic_loans.csv\")\n",
        "\n",
        "    with st.expander(\"Retrain Model\"):\n",
        "        with st.form(\"retrain_form\"):\n",
        "            dataset_options = [\"Synthetic\"] + [str(f) for f in (ROOT / \"data\" / \"uploads\").glob(\"*.[cC][sS][vV]\")]\n",
        "            dataset = st.selectbox(\"Dataset\", dataset_options)\n",
        "            version_note = st.text_input(\"Version Note\", \"admin_retrain\")\n",
        "            params = st.text_area(\"Model Params (JSON)\", '{\"max_depth\": 5, \"learning_rate\": 0.1}')\n",
        "            if st.form_submit_button(\"Train\"):\n",
        "                df = st.session_state.get(\"synthetic_df\") if dataset == \"Synthetic\" else pd.read_csv(dataset)\n",
        "                try:\n",
        "                    params = json.loads(params)\n",
        "                except:\n",
        "                    st.error(\"Invalid JSON\")\n",
        "                    st.stop()\n",
        "                with st.spinner(\"Training...\"):\n",
        "                    result = admin_tools.retrain_model(df, model_params=params, version_note=version_note)\n",
        "                if result[\"ok\"]:\n",
        "                    st.success(f\"Model {result['result']['version_id']} trained, AUC: {result['result']['auc']:.2f}\")\n",
        "                else:\n",
        "                    st.error(result[\"error\"])\n",
        "\n",
        "    with st.expander(\"Fraud Stress Test\"):\n",
        "        with st.form(\"stress_form\"):\n",
        "            base_records = st.slider(\"Base Records\", 100, 2000, 500, step=100)\n",
        "            fraud_steps = st.text_input(\"Fraud Steps (comma-separated)\", \"0.01,0.05,0.1,0.2\")\n",
        "            detection_threshold = st.slider(\"Detection Threshold\", 0.0, 1.0, 0.7, step=0.05)\n",
        "            if st.form_submit_button(\"Run Test\"):\n",
        "                steps = [float(x.strip()) for x in fraud_steps.split(\",\")]\n",
        "                with st.spinner(\"Running...\"):\n",
        "                    result = admin_tools.fraud_stress_test(base_records=base_records, fraud_steps=steps, detection_threshold=detection_threshold)\n",
        "                st.dataframe(pd.DataFrame(result))\n",
        "                st.plotly_chart(px.line(pd.DataFrame(result), x='fraud_pct', y='detection_rate', title=\"Detection Rate by Fraud %\"))\n",
        "\n",
        "    with st.expander(\"Schema Management\"):\n",
        "        with st.form(\"schema_form\"):\n",
        "            new_columns = st.text_area(\"New Expected Columns (comma-separated)\", \",\".join(schema.EXPECTED_COLUMNS))\n",
        "            tag = st.text_input(\"Schema Tag\", time.strftime('%Y%m%d_%H%M%S'))\n",
        "            if st.form_submit_button(\"Save Schema\"):\n",
        "                columns = [x.strip() for x in new_columns.split(\",\")]\n",
        "                result = admin_tools.inject_schema(columns, tag)\n",
        "                st.success(f\"Saved to {result['backup']}\")\n",
        "        backups = [json.load(open(f)) for f in SCHEMA_BACKUPS.glob(\"*.json\")]\n",
        "        if backups:\n",
        "            st.dataframe(pd.DataFrame(backups))\n",
        "\n",
        "    with st.expander(\"Impersonate User\"):\n",
        "        with st.form(\"impersonate_form\"):\n",
        "            username = st.text_input(\"Username to Impersonate\", \"demo_user\")\n",
        "            if st.form_submit_button(\"Impersonate\"):\n",
        "                result = admin_tools.impersonate_user(username)\n",
        "                st.session_state[\"impersonated_user\"] = result[\"impersonated_user\"]\n",
        "                st.success(f\"Impersonating {result['impersonated_user']}\")\n",
        "                client_panel.app()\n",
        "\"\"\")\n",
        "APP_PY.write_text(app_py, encoding=\"utf-8\")\n",
        "\n",
        "# Smoke test\n",
        "import importlib, sys\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "try:\n",
        "    import modules.app.client_panel as client_panel\n",
        "    importlib.reload(client_panel)\n",
        "    print(\"✅ Client panel imported.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Client panel failed:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoz6TU_HITAj",
        "outputId": "ada84184-bfa6-484f-e455-04dc4c305b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "👉 Open your app on: NgrokTunnel: \"https://a77eabb13ca9.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Kill any existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Set your ngrok auth token\n",
        "ngrok.set_auth_token(\"31rYvgklL0EdX9bGLvTXc313efE_2GyDFGPUNAyFgB83bikTF\")\n",
        "\n",
        "# Start Streamlit app\n",
        "process = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "# Wait a few seconds for Streamlit to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Connect ngrok to Streamlit port\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"👉 Open your app on:\", public_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqfZXbP6foYMOAedii56tR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}