{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP51Nn76ISOXdti426GHq5W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JBlizzard-sketch/LoanIQ/blob/main/Copy_of_LoanIQ2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "IxIumSHaqtW8",
        "outputId": "d9050efc-540f-4b9a-bddb-6640366aebdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed successfully.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Write the main file\\n!mkdir -p modules/bootstrap\\n!echo -e \"# modules/bootstrap/deps.py\\n$(cat << \\'EOF\\'\\nimport os\\nimport subprocess\\n\\nREQUIRED_LIBS = [\\n    \\'streamlit==1.38.0\\',\\n    \\'pandas==2.2.2\\',\\n    \\'numpy==1.26.4\\',\\n    \\'scikit-learn==1.5.1\\',\\n    \\'xgboost==2.1.1\\',\\n    \\'plotly==5.22.0\\',\\n    \\'faker==28.1.0\\',\\n    \\'openpyxl==3.1.5\\',\\n    \\'reportlab==4.2.2\\',\\n    \\'pytest==8.3.2\\',\\n    \\'shap==0.46.0\\'\\n]\\n\\ndef install_deps():\\n    os.makedirs(\\'data\\', exist_ok=True)\\n    marker_path = os.path.join(\\'data\\', \\'.deps_ok\\')\\n    \\n    if not os.path.exists(marker_path):\\n        for lib in REQUIRED_LIBS:\\n            try:\\n                __import__(lib.split(\\'==\\')[0])\\n            except ImportError:\\n                subprocess.check_call([\\'pip\\', \\'install\\', lib])\\n        with open(marker_path, \\'w\\') as f:\\n            f.write(\\'OK\\')\\n        print(\"Dependencies installed successfully.\")\\n    else:\\n        print(\"Dependencies already installed.\")\\n\\nif __name__ == \\'__main__\\':\\n    install_deps()\\nEOF\\n)\" > modules/bootstrap/deps.py\\n\\n# Write the test file\\n!mkdir -p tests\\n!echo -e \"# tests/test_bootstrap.py\\nimport os\\nimport pytest\\n\\ndef test_deps_install():\\n    from modules.bootstrap import deps\\n    deps.install_deps()\\n    marker_path = os.path.join(\\'data\\', \\'.deps_ok\\')\\n    assert os.path.exists(marker_path), \\'Marker file not created\\'\\n    with open(marker_path, \\'r\\') as f:\\n        assert f.read() == \\'OK\\', \\'Marker file content incorrect\\'\" > tests/test_bootstrap.py\\n\\n# Run the script\\n!python modules/bootstrap/deps.py\\n\\n# Run the test\\n!pytest tests/test_bootstrap.py -v\\n\\n# Verify marker file\\n!ls data\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\n",
        "# Colab cell to create, run, and test modules/bootstrap/deps.py\n",
        "# Run this entire block in Colab to execute all steps\n",
        "\n",
        "# %%writefile modules/bootstrap/deps.py\n",
        "# Estimated line count: 50\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# List of required free libraries\n",
        "REQUIRED_LIBS = [\n",
        "    'streamlit==1.38.0',\n",
        "    'pandas==2.2.2',\n",
        "    'numpy==1.26.4',\n",
        "    'scikit-learn==1.5.1',\n",
        "    'xgboost==2.1.1',\n",
        "    'plotly==5.22.0',\n",
        "    'faker==28.1.0',\n",
        "    'openpyxl==3.1.5',\n",
        "    'reportlab==4.2.2',\n",
        "    'pytest==8.3.2',\n",
        "    'shap==0.46.0'  # For explainability\n",
        "]\n",
        "\n",
        "def install_deps():\n",
        "    \"\"\"Install required libraries and create marker file.\"\"\"\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    marker_path = os.path.join('data', '.deps_ok')\n",
        "\n",
        "    if not os.path.exists(marker_path):\n",
        "        for lib in REQUIRED_LIBS:\n",
        "            try:\n",
        "                __import__(lib.split('==')[0])\n",
        "            except ImportError:\n",
        "                subprocess.check_call(['pip', 'install', lib])\n",
        "        with open(marker_path, 'w') as f:\n",
        "            f.write('OK')\n",
        "        print(\"Dependencies installed successfully.\")\n",
        "    else:\n",
        "        print(\"Dependencies already installed.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    install_deps()\n",
        "\n",
        "# Test code (will be written to tests/test_bootstrap.py)\n",
        "\"\"\"\n",
        "# tests/test_bootstrap.py\n",
        "import os\n",
        "import pytest\n",
        "\n",
        "def test_deps_install():\n",
        "    from modules.bootstrap import deps\n",
        "    deps.install_deps()\n",
        "    marker_path = os.path.join('data', '.deps_ok')\n",
        "    assert os.path.exists(marker_path), \"Marker file not created\"\n",
        "    with open(marker_path, 'r') as f:\n",
        "        assert f.read() == 'OK', \"Marker file content incorrect\"\n",
        "\"\"\"\n",
        "\n",
        "# Colab commands to execute (included in this cell)\n",
        "\"\"\"\n",
        "# Write the main file\n",
        "!mkdir -p modules/bootstrap\n",
        "!echo -e \"# modules/bootstrap/deps.py\\n$(cat << 'EOF'\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "REQUIRED_LIBS = [\n",
        "    'streamlit==1.38.0',\n",
        "    'pandas==2.2.2',\n",
        "    'numpy==1.26.4',\n",
        "    'scikit-learn==1.5.1',\n",
        "    'xgboost==2.1.1',\n",
        "    'plotly==5.22.0',\n",
        "    'faker==28.1.0',\n",
        "    'openpyxl==3.1.5',\n",
        "    'reportlab==4.2.2',\n",
        "    'pytest==8.3.2',\n",
        "    'shap==0.46.0'\n",
        "]\n",
        "\n",
        "def install_deps():\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    marker_path = os.path.join('data', '.deps_ok')\n",
        "\n",
        "    if not os.path.exists(marker_path):\n",
        "        for lib in REQUIRED_LIBS:\n",
        "            try:\n",
        "                __import__(lib.split('==')[0])\n",
        "            except ImportError:\n",
        "                subprocess.check_call(['pip', 'install', lib])\n",
        "        with open(marker_path, 'w') as f:\n",
        "            f.write('OK')\n",
        "        print(\"Dependencies installed successfully.\")\n",
        "    else:\n",
        "        print(\"Dependencies already installed.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    install_deps()\n",
        "EOF\n",
        ")\" > modules/bootstrap/deps.py\n",
        "\n",
        "# Write the test file\n",
        "!mkdir -p tests\n",
        "!echo -e \"# tests/test_bootstrap.py\\nimport os\\nimport pytest\\n\\ndef test_deps_install():\\n    from modules.bootstrap import deps\\n    deps.install_deps()\\n    marker_path = os.path.join('data', '.deps_ok')\\n    assert os.path.exists(marker_path), 'Marker file not created'\\n    with open(marker_path, 'r') as f:\\n        assert f.read() == 'OK', 'Marker file content incorrect'\" > tests/test_bootstrap.py\n",
        "\n",
        "# Run the script\n",
        "!python modules/bootstrap/deps.py\n",
        "\n",
        "# Run the test\n",
        "!pytest tests/test_bootstrap.py -v\n",
        "\n",
        "# Verify marker file\n",
        "!ls data\n",
        "\"\"\"\n",
        "\n",
        "# Expected output:\n",
        "# Dependencies installed successfully.\n",
        "# ============================= test session starts =============================\n",
        "# tests/test_bootstrap.py::test_deps_install PASSED\n",
        "# =========================== 1 passed in 0.XXs ===========================\n",
        "# .deps_ok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Up# Colab cell to create, run, and test modules/bootstrap/drive_persist.py and modules/bootstrap/tunnel.py\n",
        "# Run this entire block in Colab to execute all steps\n",
        "\n",
        "# %%writefile modules/bootstrap/drive_persist.py\n",
        "# Estimated line count: 80\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "import hashlib\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "class DrivePersist:\n",
        "    \"\"\"Manage Google Drive persistence for Colab with atomic writes and retries.\"\"\"\n",
        "    DRIVE_ROOT = \"/content/drive/MyDrive/loan_iq\"\n",
        "    MOUNT_PATH = \"/content/drive\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Mount Drive and ensure root directory.\"\"\"\n",
        "        if not os.path.exists(self.MOUNT_PATH):\n",
        "            drive.mount(self.MOUNT_PATH)\n",
        "        os.makedirs(self.DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "    def persist_path(self, local_path):\n",
        "        \"\"\"Get Drive path for a local file.\"\"\"\n",
        "        relative_path = os.path.relpath(local_path, start=os.getcwd())\n",
        "        return os.path.join(self.DRIVE_ROOT, relative_path)\n",
        "\n",
        "    def save_file(self, local_path, data, max_retries=3):\n",
        "        \"\"\"Save data to Drive with atomic writes and retries.\"\"\"\n",
        "        drive_path = self.persist_path(local_path)\n",
        "        os.makedirs(os.path.dirname(drive_path), exist_ok=True)\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                temp_path = drive_path + '.tmp'\n",
        "                with open(temp_path, 'wb') as f:\n",
        "                    pickle.dump(data, f)\n",
        "                os.rename(temp_path, drive_path)\n",
        "\n",
        "                # Compute and save hash\n",
        "                file_hash = hashlib.md5(str(data).encode()).hexdigest()\n",
        "                with open(drive_path + '.hash', 'w') as f:\n",
        "                    f.write(file_hash)\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"Retry {attempt + 1}/{max_retries} for {drive_path}: {e}\")\n",
        "                time.sleep(1)\n",
        "        return False\n",
        "\n",
        "    def load_file(self, local_path):\n",
        "        \"\"\"Load data from Drive, verify hash.\"\"\"\n",
        "        drive_path = self.persist_path(local_path)\n",
        "        if not os.path.exists(drive_path):\n",
        "            return None\n",
        "        try:\n",
        "            with open(drive_path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "            hash_path = drive_path + '.hash'\n",
        "            if os.path.exists(hash_path):\n",
        "                with open(hash_path, 'r') as f:\n",
        "                    stored_hash = f.read()\n",
        "                current_hash = hashlib.md5(str(data).encode()).hexdigest()\n",
        "                if stored_hash != current_hash:\n",
        "                    print(f\"Hash mismatch for {drive_path}\")\n",
        "                    return None\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {drive_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    persist = DrivePersist()\n",
        "    test_data = {'test': 'data'}\n",
        "    test_path = os.path.join('data', 'test.pkl')\n",
        "    persist.save_file(test_path, test_data)\n",
        "    print(f\"Saved to {persist.persist_path(test_path)}\")\n",
        "    loaded = persist.load_file(test_path)\n",
        "    print(f\"Loaded: {loaded}\")\n",
        "\n",
        "# %%writefile modules/bootstrap/tunnel.py\n",
        "# Estimated line count: 60\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"31rYvgklL0EdX9bGLvTXc313efE_2GyDFGPUNAyFgB83bikTF\"\n",
        "\n",
        "def setup_tunnel(port=8501):\n",
        "    \"\"\"Set up Ngrok tunnel for Streamlit with hardcoded authtoken.\"\"\"\n",
        "    try:\n",
        "        subprocess.check_call(['pip', 'install', 'pyngrok==7.2.0'])\n",
        "        from pyngrok import ngrok\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "        # Terminate existing tunnels\n",
        "        ngrok.kill()\n",
        "\n",
        "        # Start new tunnel\n",
        "        tunnel = ngrok.connect(port, bind_tls=True)\n",
        "        public_url = tunnel.public_url\n",
        "        print(f\"Streamlit accessible at: {public_url}\")\n",
        "        return public_url\n",
        "    except Exception as e:\n",
        "        print(f\"Tunnel setup failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_new_tunnel_url():\n",
        "    \"\"\"Command to get new Ngrok URL (for README/runbook).\"\"\"\n",
        "    cmd = f\"!ngrok http 8501 --authtoken {NGROK_AUTH_TOKEN}\"\n",
        "    print(f\"Run this in Colab to get new URL:\\n{cmd}\")\n",
        "    return cmd\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    setup_tunnel()\n",
        "    get_new_tunnel_url()\n",
        "\n",
        "# Test code (will be written to tests/test_bootstrap.py)\n",
        "\"\"\"\n",
        "# tests/test_bootstrap.py\n",
        "import os\n",
        "import pytest\n",
        "from modules.bootstrap import drive_persist, tunnel\n",
        "\n",
        "def test_drive_persist():\n",
        "    persist = drive_persist.DrivePersist()\n",
        "    test_data = {'test': 'data'}\n",
        "    test_path = os.path.join('data', 'test.pkl')\n",
        "    assert persist.save_file(test_path, test_data), \"Failed to save to Drive\"\n",
        "    loaded = persist.load_file(test_path)\n",
        "    assert loaded == test_data, \"Loaded data mismatch\"\n",
        "    assert os.path.exists(persist.persist_path(test_path) + '.hash'), \"Hash file missing\"\n",
        "\n",
        "def test_tunnel_setup():\n",
        "    public_url = tunnel.setup_tunnel()\n",
        "    assert public_url is None or isinstance(public_url, str), \"Invalid tunnel URL\"\n",
        "    cmd = tunnel.get_new_tunnel_url()\n",
        "    assert NGROK_AUTH_TOKEN in cmd, \"Ngrok authtoken not in command\"\n",
        "\"\"\"\n",
        "\n",
        "# Colab commands to execute (run this entire cell)\n",
        "\"\"\"\n",
        "# Create directories\n",
        "!mkdir -p modules/bootstrap tests data\n",
        "\n",
        "# Write drive_persist.py\n",
        "!echo -e \"# modules/bootstrap/drive_persist.py\\n$(cat << 'EOF'\n",
        "import os\n",
        "from google.colab import drive\n",
        "import hashlib\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "class DrivePersist:\n",
        "    DRIVE_ROOT = \\\"/content/drive/MyDrive/loan_iq\\\"\n",
        "    MOUNT_PATH = \\\"/content/drive\\\"\n",
        "\n",
        "    def __init__(self):\n",
        "        if not os.path.exists(self.MOUNT_PATH):\n",
        "            drive.mount(self.MOUNT_PATH)\n",
        "        os.makedirs(self.DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "    def persist_path(self, local_path):\n",
        "        relative_path = os.path.relpath(local_path, start=os.getcwd())\n",
        "        return os.path.join(self.DRIVE_ROOT, relative_path)\n",
        "\n",
        "    def save_file(self, local_path, data, max_retries=3):\n",
        "        os.makedirs(os.path.dirname(drive_path), exist_ok=True)\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                temp_path = drive_path + '.tmp'\n",
        "                with open(temp_path, 'wb') as f:\n",
        "                    pickle.dump(data, f)\n",
        "                os.rename(temp_path, drive_path)\n",
        "                file_hash = hashlib.md5(str(data).encode()).hexdigest()\n",
        "                with open(drive_path + '.hash', 'w') as f:\n",
        "                    f.write(file_hash)\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\\\"Retry {attempt + 1}/{max_retries} for {drive_path}: {e}\\\")\n",
        "                time.sleep(1)\n",
        "        return False\n",
        "\n",
        "    def load_file(self, local_path):\n",
        "        drive_path = self.persist_path(local_path)\n",
        "        if not os.path.exists(drive_path):\n",
        "            return None\n",
        "        try:\n",
        "            with open(drive_path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "            hash_path = drive_path + '.hash'\n",
        "            if os.path.exists(hash_path):\n",
        "                with open(hash_path, 'r') as f:\n",
        "                    stored_hash = f.read()\n",
        "                current_hash = hashlib.md5(str(data).encode()).hexdigest()\n",
        "                if stored_hash != current_hash:\n",
        "                    print(f\\\"Hash mismatch for {drive_path}\\\")\n",
        "                    return None\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            print(f\\\"Error loading {drive_path}: {e}\\\")\n",
        "            return None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    persist = DrivePersist()\n",
        "    test_data = {'test': 'data'}\n",
        "    test_path = os.path.join('data', 'test.pkl')\n",
        "    persist.save_file(test_path, test_data)\n",
        "    print(f\\\"Saved to {persist.persist_path(test_path)}\\\")\n",
        "    loaded = persist.load_file(test_path)\n",
        "    print(f\\\"Loaded: {loaded}\\\")\n",
        "EOF\n",
        ")\" > modules/bootstrap/drive_persist.py\n",
        "\n",
        "# Write tunnel.py\n",
        "!echo -e \"# modules/bootstrap/tunnel.py\\n$(cat << 'EOF'\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "NGROK_AUTH_TOKEN = \\\"31rYvgklL0EdX9bGLvTXc313efE_2GyDFGPUNAyFgB83bikTF\\\"\n",
        "\n",
        "def setup_tunnel(port=8501):\n",
        "    try:\n",
        "        subprocess.check_call(['pip', 'install', 'pyngrok==7.2.0'])\n",
        "        from pyngrok import ngrok\n",
        "        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "        ngrok.kill()\n",
        "        tunnel = ngrok.connect(port, bind_tls=True)\n",
        "        public_url = tunnel.public_url\n",
        "        print(f\\\"Streamlit accessible at: {public_url}\\\")\n",
        "        return public_url\n",
        "    except Exception as e:\n",
        "        print(f\\\"Tunnel setup failed: {e}\\\")\n",
        "        return None\n",
        "\n",
        "def get_new_tunnel_url():\n",
        "    cmd = f\\\"!ngrok http 8501 --authtoken {NGROK_AUTH_TOKEN}\\\"\n",
        "    print(f\\\"Run this in Colab to get new URL:\\n{cmd}\\\")\n",
        "    return cmd\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    setup_tunnel()\n",
        "    get_new_tunnel_url()\n",
        "EOF\n",
        ")\" > modules/bootstrap/tunnel.py\n",
        "\n",
        "# Write test file (appending to existing test_bootstrap.py)\n",
        "!echo -e \"# tests/test_bootstrap.py\\n$(cat << 'EOF'\n",
        "import os\n",
        "import pytest\n",
        "from modules.bootstrap import drive_persist, tunnel\n",
        "\n",
        "def test_deps_install():\n",
        "    from modules.bootstrap import deps\n",
        "    deps.install_deps()\n",
        "    marker_path = os.path.join('data', '.deps_ok')\n",
        "    assert os.path.exists(marker_path), 'Marker file not created'\n",
        "    with open(marker_path, 'r') as f:\n",
        "        assert f.read() == 'OK', 'Marker file content incorrect'\n",
        "\n",
        "def test_drive_persist():\n",
        "    persist = drive_persist.DrivePersist()\n",
        "    test_data = {'test': 'data'}\n",
        "    test_path = os.path.join('data', 'test.pkl')\n",
        "    assert persist.save_file(test_path, test_data), 'Failed to save to Drive'\n",
        "    loaded = persist.load_file(test_path)\n",
        "    assert loaded == test_data, 'Loaded data mismatch'\n",
        "    assert os.path.exists(persist.persist_path(test_path) + '.hash'), 'Hash file missing'\n",
        "\n",
        "def test_tunnel_setup():\n",
        "    public_url = tunnel.setup_tunnel()\n",
        "    assert public_url is None or isinstance(public_url, str), 'Invalid tunnel URL'\n",
        "    cmd = tunnel.get_new_tunnel_url()\n",
        "    assert NGROK_AUTH_TOKEN in cmd, 'Ngrok authtoken not in command'\n",
        "EOF\n",
        ")\" > tests/test_bootstrap.py\n",
        "\n",
        "# Run dependencies (ensure environment)\n",
        "!python modules/bootstrap/deps.py\n",
        "\n",
        "# Run drive_persist.py (will prompt for Google Drive auth code)\n",
        "!python modules/bootstrap/drive_persist.py\n",
        "\n",
        "# Run tunnel.py (may take time to set up Ngrok)\n",
        "!python modules/bootstrap/tunnel.py\n",
        "\n",
        "# Run tests\n",
        "!pytest tests/test_bootstrap.py -v\n",
        "\n",
        "# Verify files\n",
        "!ls data\n",
        "!ls modules/bootstrap\n",
        "\"\"\"\n",
        "\n",
        "# Expected output:\n",
        "# Dependencies installed successfully.\n",
        "# Mounted at /content/drive\n",
        "# Saved to /content/drive/MyDrive/loan_iq/data/test.pkl\n",
        "# Loaded: {'test': 'data'}\n",
        "# Streamlit accessible at: https://<ngrok-url>.ngrok.io\n",
        "# Run this in Colab to get new URL:\n",
        "# !ngrok http 8501 --authtoken 31rYvgklL0EdX9bGLvTXc313efE_2GyDFGPUNAyFgB83bikTF\n",
        "# ============================= test session starts =============================\n",
        "# tests/test_bootstrap.py::test_deps_install PASSED\n",
        "# tests/test_bootstrap.py::test_drive_persist PASSED\n",
        "# tests/test_bootstrap.py::test_tunnel_setup PASSED\n",
        "# =========================== 3 passed in 0.XXs ===========================\n",
        "# test.pkl  test.pkl.hash  .deps_ok\n",
        "# deps.py  drive_persist.py  tunnel.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "b2epouRCrnHJ",
        "outputId": "ea1d5b6d-56e5-427b-b5f6-784e0715699a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Saved to /content/drive/MyDrive/loan_iq/data/test.pkl\n",
            "Loaded: {'test': 'data'}\n",
            "Streamlit accessible at: https://f7e668fceeb4.ngrok-free.app\n",
            "Run this in Colab to get new URL:\n",
            "!ngrok http 8501 --authtoken 31rYvgklL0EdX9bGLvTXc313efE_2GyDFGPUNAyFgB83bikTF\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Create directories\\n!mkdir -p modules/bootstrap tests data\\n\\n# Write drive_persist.py\\n!echo -e \"# modules/bootstrap/drive_persist.py\\n$(cat << \\'EOF\\'\\nimport os\\nfrom google.colab import drive\\nimport hashlib\\nimport pickle\\nimport time\\n\\nclass DrivePersist:\\n    DRIVE_ROOT = \"/content/drive/MyDrive/loan_iq\"\\n    MOUNT_PATH = \"/content/drive\"\\n    \\n    def __init__(self):\\n        if not os.path.exists(self.MOUNT_PATH):\\n            drive.mount(self.MOUNT_PATH)\\n        os.makedirs(self.DRIVE_ROOT, exist_ok=True)\\n    \\n    def persist_path(self, local_path):\\n        relative_path = os.path.relpath(local_path, start=os.getcwd())\\n        return os.path.join(self.DRIVE_ROOT, relative_path)\\n    \\n    def save_file(self, local_path, data, max_retries=3):\\n        os.makedirs(os.path.dirname(drive_path), exist_ok=True)\\n        for attempt in range(max_retries):\\n            try:\\n                temp_path = drive_path + \\'.tmp\\'\\n                with open(temp_path, \\'wb\\') as f:\\n                    pickle.dump(data, f)\\n                os.rename(temp_path, drive_path)\\n                file_hash = hashlib.md5(str(data).encode()).hexdigest()\\n                with open(drive_path + \\'.hash\\', \\'w\\') as f:\\n                    f.write(file_hash)\\n                return True\\n            except Exception as e:\\n                print(f\"Retry {attempt + 1}/{max_retries} for {drive_path}: {e}\")\\n                time.sleep(1)\\n        return False\\n    \\n    def load_file(self, local_path):\\n        drive_path = self.persist_path(local_path)\\n        if not os.path.exists(drive_path):\\n            return None\\n        try:\\n            with open(drive_path, \\'rb\\') as f:\\n                data = pickle.load(f)\\n            hash_path = drive_path + \\'.hash\\'\\n            if os.path.exists(hash_path):\\n                with open(hash_path, \\'r\\') as f:\\n                    stored_hash = f.read()\\n                current_hash = hashlib.md5(str(data).encode()).hexdigest()\\n                if stored_hash != current_hash:\\n                    print(f\"Hash mismatch for {drive_path}\")\\n                    return None\\n            return data\\n        except Exception as e:\\n            print(f\"Error loading {drive_path}: {e}\")\\n            return None\\n\\nif __name__ == \\'__main__\\':\\n    persist = DrivePersist()\\n    test_data = {\\'test\\': \\'data\\'}\\n    test_path = os.path.join(\\'data\\', \\'test.pkl\\')\\n    persist.save_file(test_path, test_data)\\n    print(f\"Saved to {persist.persist_path(test_path)}\")\\n    loaded = persist.load_file(test_path)\\n    print(f\"Loaded: {loaded}\")\\nEOF\\n)\" > modules/bootstrap/drive_persist.py\\n\\n# Write tunnel.py\\n!echo -e \"# modules/bootstrap/tunnel.py\\n$(cat << \\'EOF\\'\\nimport os\\nimport subprocess\\nimport time\\n\\nNGROK_AUTH_TOKEN = \"31rYvgklL0EdX9bGLvTXc313efE_2GyDFGPUNAyFgB83bikTF\"\\n\\ndef setup_tunnel(port=8501):\\n    try:\\n        subprocess.check_call([\\'pip\\', \\'install\\', \\'pyngrok==7.2.0\\'])\\n        from pyngrok import ngrok\\n        ngrok.set_auth_token(NGROK_AUTH_TOKEN)\\n        ngrok.kill()\\n        tunnel = ngrok.connect(port, bind_tls=True)\\n        public_url = tunnel.public_url\\n        print(f\"Streamlit accessible at: {public_url}\")\\n        return public_url\\n    except Exception as e:\\n        print(f\"Tunnel setup failed: {e}\")\\n        return None\\n\\ndef get_new_tunnel_url():\\n    cmd = f\"!ngrok http 8501 --authtoken {NGROK_AUTH_TOKEN}\"\\n    print(f\"Run this in Colab to get new URL:\\n{cmd}\")\\n    return cmd\\n\\nif __name__ == \\'__main__\\':\\n    setup_tunnel()\\n    get_new_tunnel_url()\\nEOF\\n)\" > modules/bootstrap/tunnel.py\\n\\n# Write test file (appending to existing test_bootstrap.py)\\n!echo -e \"# tests/test_bootstrap.py\\n$(cat << \\'EOF\\'\\nimport os\\nimport pytest\\nfrom modules.bootstrap import drive_persist, tunnel\\n\\ndef test_deps_install():\\n    from modules.bootstrap import deps\\n    deps.install_deps()\\n    marker_path = os.path.join(\\'data\\', \\'.deps_ok\\')\\n    assert os.path.exists(marker_path), \\'Marker file not created\\'\\n    with open(marker_path, \\'r\\') as f:\\n        assert f.read() == \\'OK\\', \\'Marker file content incorrect\\'\\n\\ndef test_drive_persist():\\n    persist = drive_persist.DrivePersist()\\n    test_data = {\\'test\\': \\'data\\'}\\n    test_path = os.path.join(\\'data\\', \\'test.pkl\\')\\n    assert persist.save_file(test_path, test_data), \\'Failed to save to Drive\\'\\n    loaded = persist.load_file(test_path)\\n    assert loaded == test_data, \\'Loaded data mismatch\\'\\n    assert os.path.exists(persist.persist_path(test_path) + \\'.hash\\'), \\'Hash file missing\\'\\n\\ndef test_tunnel_setup():\\n    public_url = tunnel.setup_tunnel()\\n    assert public_url is None or isinstance(public_url, str), \\'Invalid tunnel URL\\'\\n    cmd = tunnel.get_new_tunnel_url()\\n    assert NGROK_AUTH_TOKEN in cmd, \\'Ngrok authtoken not in command\\'\\nEOF\\n)\" > tests/test_bootstrap.py\\n\\n# Run dependencies (ensure environment)\\n!python modules/bootstrap/deps.py\\n\\n# Run drive_persist.py (will prompt for Google Drive auth code)\\n!python modules/bootstrap/drive_persist.py\\n\\n# Run tunnel.py (may take time to set up Ngrok)\\n!python modules/bootstrap/tunnel.py\\n\\n# Run tests\\n!pytest tests/test_bootstrap.py -v\\n\\n# Verify files\\n!ls data\\n!ls modules/bootstrap\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell to create, run, and test modules/core/config.py and modules/core/db.py\n",
        "# Run this entire block in Colab to execute all steps\n",
        "\n",
        "# Ensure Python path includes current directory for module imports\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "# Create directories to prevent path errors\n",
        "!mkdir -p modules/core tests data models data/reports\n",
        "!ls modules/core || echo \"Directory modules/core created\"\n",
        "!ls data || echo \"Directory data created\"\n",
        "\n",
        "# Write config.py\n",
        "!echo -e \"# modules/core/config.py\\n# Estimated line count: 60\\n\\nimport sys\\nimport os\\nsys.path.append(os.getcwd())\\nimport random\\nimport numpy as np\\n\\n# Hardcoded admin credentials\\nADMIN_CREDENTIALS = {\\n    \\\"username\\\": \\\"admin\\\",\\n    \\\"password\\\": \\\"Shady868\\\"\\n}\\n\\n# Random seeds for reproducibility\\nSEEDS = {\\n    \\\"faker\\\": 42,\\n    \\\"numpy\\\": 42,\\n    \\\"random\\\": 42\\n}\\n\\n# App configuration\\nCONFIG = {\\n    \\\"data_dir\\\": os.path.join(\\\"data\\\"),\\n    \\\"model_dir\\\": os.path.join(\\\"models\\\"),\\n    \\\"report_dir\\\": os.path.join(\\\"data\\\", \\\"reports\\\"),\\n    \\\"db_path\\\": os.path.join(\\\"data\\\", \\\"loan_iq.db\\\"),\\n    \\\"drive_root\\\": \\\"/content/drive/MyDrive/loan_iq\\\",\\n    \\\"streamlit_port\\\": 8501,\\n    \\\"fraud_types\\\": [\\\"ghost_client\\\", \\\"duplicate_id\\\", \\\"missed_payment\\\", \\\"identity_theft\\\"],\\n    \\\"regions\\\": [\\\"urban\\\", \\\"rural\\\", \\\"semi_urban\\\"],\\n    \\\"max_clients_batch\\\": 70000,\\n    \\\"default_batch_size\\\": 1000\\n}\\n\\ndef init_seeds():\\n    \\\"\\\"\\\"Initialize random seeds for reproducibility.\\\"\\\"\\\"\\n    random.seed(SEEDS[\\\"random\\\"])\\n    np.random.seed(SEEDS[\\\"numpy\\\"])\\n\\ndef get_config():\\n    \\\"\\\"\\\"Return config dictionary, ensure directories exist.\\\"\\\"\\\"\\n    os.makedirs(CONFIG[\\\"data_dir\\\"], exist_ok=True)\\n    os.makedirs(CONFIG[\\\"model_dir\\\"], exist_ok=True)\\n    os.makedirs(CONFIG[\\\"report_dir\\\"], exist_ok=True)\\n    return CONFIG\\n\\nif __name__ == \\\"__main__\\\":\\n    init_seeds()\\n    config = get_config()\\n    print(f\\\"Config loaded: {config}\\\")\" > modules/core/config.py\n",
        "\n",
        "# Write db.py\n",
        "!echo -e \"# modules/core/db.py\\n# Estimated line count: 120\\n\\nimport sys\\nimport os\\nsys.path.append(os.getcwd())\\nimport sqlite3\\nimport json\\nfrom datetime import datetime\\ntry:\\n    from modules.core import config\\nexcept ImportError as e:\\n    print(f\\\"Import error: {e}\\\")\\n    raise\\n\\nclass DB:\\n    \\\"\\\"\\\"SQLite database wrapper for Loan IQ.\\\"\\\"\\\"\\n    def __init__(self):\\n        print(f\\\"sys.path: {sys.path}\\\")  # Debug path\\n        self.db_path = config.get_config()[\\\"db_path\\\"]\\n        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\\n        self.conn = sqlite3.connect(self.db_path)\\n        self.cursor = self.conn.cursor()\\n        self.create_tables()\\n\\n    def create_tables(self):\\n        \\\"\\\"\\\"Create database tables.\\\"\\\"\\\"\\n        tables = [\\n            \\\"CREATE TABLE IF NOT EXISTS users (user_id INTEGER PRIMARY KEY, username TEXT UNIQUE, password TEXT, role TEXT)\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS clients (client_id TEXT PRIMARY KEY, name TEXT, branch TEXT, region TEXT, income REAL, created_at TIMESTAMP)\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS loans (loan_id TEXT PRIMARY KEY, client_id TEXT, amount REAL, status TEXT, start_date TIMESTAMP, FOREIGN KEY (client_id) REFERENCES clients(client_id))\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS transactions (transaction_id TEXT PRIMARY KEY, loan_id TEXT, amount REAL, date TIMESTAMP, type TEXT, FOREIGN KEY (loan_id) REFERENCES loans(loan_id))\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS models (model_id TEXT PRIMARY KEY, type TEXT, version TEXT, created_at TIMESTAMP)\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS model_versions (version_id TEXT PRIMARY KEY, model_id TEXT, config_json TEXT, data_hash TEXT, metrics_json TEXT, commit_ref TEXT, comments TEXT, created_at TIMESTAMP, FOREIGN KEY (model_id) REFERENCES models(model_id))\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS audit_logs (log_id INTEGER PRIMARY KEY AUTOINCREMENT, actor_id TEXT, actor_role TEXT, action TEXT, target_id TEXT, target_type TEXT, reason TEXT, timestamp TIMESTAMP, before_snapshot TEXT, after_snapshot TEXT, reversible BOOLEAN, reversal_id INTEGER)\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS simulations (sim_id TEXT PRIMARY KEY, user_id TEXT, params_json TEXT, created_at TIMESTAMP)\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS reports (report_id TEXT PRIMARY KEY, type TEXT, path TEXT, created_at TIMESTAMP)\\\",\\n            \\\"CREATE TABLE IF NOT EXISTS assets (asset_id TEXT PRIMARY KEY, path TEXT, type TEXT, created_at TIMESTAMP)\\\"\\n        ]\\n        for table_sql in tables:\\n            self.cursor.execute(table_sql)\\n        self.conn.commit()\\n\\n    def log_action(self, actor_id, actor_role, action, target_id, target_type, reason, before_snapshot, after_snapshot, reversible=False):\\n        \\\"\\\"\\\"Log an admin action to audit_logs.\\\"\\\"\\\"\\n        timestamp = datetime.utcnow().isoformat()\\n        snapshot_before = json.dumps(before_snapshot) if before_snapshot else \\\"\\\"\\n        snapshot_after = json.dumps(after_snapshot) if after_snapshot else \\\"\\\"\\n        self.cursor.execute(\\n            \\\"INSERT INTO audit_logs (actor_id, actor_role, action, target_id, target_type, reason, timestamp, before_snapshot, after_snapshot, reversible) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\\\",\\n            (actor_id, actor_role, action, target_id, target_type, reason, timestamp, snapshot_before, snapshot_after, reversible)\\n        )\\n        self.conn.commit()\\n        return self.cursor.lastrowid\\n\\n    def get_audit_trail(self, target_id=None, target_type=None):\\n        \\\"\\\"\\\"Retrieve audit logs, optionally filtered.\\\"\\\"\\\"\\n        query = \\\"SELECT * FROM audit_logs\\\"\\n        params = []\\n        if target_id and target_type:\\n            query += \\\" WHERE target_id = ? AND target_type = ?\\\"\\n            params = [target_id, target_type]\\n        self.cursor.execute(query, params)\\n        return self.cursor.fetchall()\\n\\n    def rollback_action(self, action_id):\\n        \\\"\\\"\\\"Attempt to rollback an action if reversible.\\\"\\\"\\\"\\n        self.cursor.execute(\\\"SELECT reversible, before_snapshot, target_id, target_type, action FROM audit_logs WHERE log_id = ?\\\", (action_id,))\\n        result = self.cursor.fetchone()\\n        if not result or not result[0]:\\n            return False\\n        before_snapshot = json.loads(result[1]) if result[1] else {}\\n        target_id, target_type, action = result[2], result[3], result[4]\\n        if target_type == \\\"user\\\" and action == \\\"edit\\\":\\n            self.cursor.execute(\\\"UPDATE users SET username = ?, password = ?, role = ? WHERE user_id = ?\\\",\\n                              (before_snapshot.get(\\\"username\\\"), before_snapshot.get(\\\"password\\\"), before_snapshot.get(\\\"role\\\"), target_id))\\n            self.conn.commit()\\n            return True\\n        return False\\n\\n    def close(self):\\n        \\\"\\\"\\\"Close database connection.\\\"\\\"\\\"\\n        self.conn.close()\\n\\nif __name__ == \\\"__main__\\\":\\n    db = DB()\\n    db.cursor.execute(\\\"INSERT OR IGNORE INTO users (user_id, username, password, role) VALUES (?, ?, ?, ?)\\\",\\n                     (1, \\\"admin\\\", \\\"Shady868\\\", \\\"admin\\\"))\\n    db.conn.commit()\\n    db.log_action(\\\"1\\\", \\\"admin\\\", \\\"init\\\", \\\"1\\\", \\\"user\\\", \\\"Initialize admin user\\\", {}, {\\\"username\\\": \\\"admin\\\"})\\n    print(\\\"Database initialized.\\\")\\n    db.close()\" > modules/core/db.py\n",
        "\n",
        "# Write test file\n",
        "!echo -e \"# tests/test_core.py\\n# Estimated line count: 20\\n\\nimport sys\\nimport os\\nsys.path.append(os.getcwd())\\nfrom modules.core import config, db\\n\\ndef test_config_init():\\n    cfg = config.get_config()\\n    assert os.path.exists(cfg[\\\"data_dir\\\"]), \\\"Data directory not created\\\"\\n    assert cfg[\\\"streamlit_port\\\"] == 8501, \\\"Incorrect port\\\"\\n    assert config.ADMIN_CREDENTIALS[\\\"username\\\"] == \\\"admin\\\", \\\"Admin username incorrect\\\"\\n\\ndef test_db_create_and_log():\\n    database = db.DB()\\n    database.cursor.execute(\\\"SELECT name FROM sqlite_master WHERE type='table' AND name='audit_logs'\\\")\\n    assert database.cursor.fetchone(), \\\"Audit logs table not created\\\"\\n    log_id = database.log_action(\\\"1\\\", \\\"admin\\\", \\\"test_action\\\", \\\"test_id\\\", \\\"test_type\\\", \\\"Test reason\\\", {\\\"key\\\": \\\"before\\\"}, {\\\"key\\\": \\\"after\\\"}, True)\\n    assert log_id, \\\"Failed to log action\\\"\\n    audit_logs = database.get_audit_trail(\\\"test_id\\\", \\\"test_type\\\")\\n    assert len(audit_logs) > 0, \\\"Audit log not recorded\\\"\\n    database.close()\" > tests/test_core.py\n",
        "\n",
        "# Ensure dependencies are installed\n",
        "!python modules/bootstrap/deps.py\n",
        "\n",
        "# Verify directories\n",
        "!ls modules/core || echo \"modules/core not found\"\n",
        "!ls data || echo \"data not found\"\n",
        "\n",
        "# Run config.py\n",
        "!python modules/core/config.py\n",
        "\n",
        "# Run db.py\n",
        "!python modules/core/db.py\n",
        "\n",
        "# Run tests\n",
        "!pytest tests/test_core.py -v\n",
        "\n",
        "# Verify files\n",
        "!ls modules/core\n",
        "!ls data\n",
        "\n",
        "# Expected output:\n",
        "# Dependencies installed successfully.\n",
        "# modules/core created\n",
        "# data created\n",
        "# Config loaded: {'data_dir': 'data', 'model_dir': 'models', 'report_dir': 'data/reports', 'db_path': 'data/loan_iq.db', 'drive_root': '/content/drive/MyDrive/loan_iq', 'streamlit_port': 8501, 'fraud_types': ['ghost_client', 'duplicate_id', 'missed_payment', 'identity_theft'], 'regions': ['urban', 'rural', 'semi_urban'], 'max_clients_batch': 70000, 'default_batch_size': 1000}\n",
        "# sys.path: [...'/content'...]\n",
        "# Database initialized.\n",
        "# ============================= test session starts =============================\n",
        "# tests/test_core.py::test_config_init PASSED\n",
        "# tests/test_core.py::test_db_create_and_log PASSED\n",
        "# =========================== 2 passed in 0.XXs ===========================\n",
        "# config.py  db.py\n",
        "# .deps_ok  loan_iq.db  reports"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyW3tlN8uLtz",
        "outputId": "76c2eb26-287d-4539-b47a-4003f49a03ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reports\n",
            "python3: can't open file '/content/modules/bootstrap/deps.py': [Errno 2] No such file or directory\n",
            "config.py  db.py\n",
            "reports\n",
            "Config loaded: {'data_dir': 'data', 'model_dir': 'models', 'report_dir': 'data/reports', 'db_path': 'data/loan_iq.db', 'drive_root': '/content/drive/MyDrive/loan_iq', 'streamlit_port': 8501, 'fraud_types': ['ghost_client', 'duplicate_id', 'missed_payment', 'identity_theft'], 'regions': ['urban', 'rural', 'semi_urban'], 'max_clients_batch': 70000, 'default_batch_size': 1000}\n",
            "sys.path: ['/content/modules/core', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content']\n",
            "/content/modules/core/db.py:46: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  timestamp = datetime.utcnow().isoformat()\n",
            "Database initialized.\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: Faker-28.1.0, anyio-4.10.0, typeguard-4.4.4, langsmith-0.4.16\n",
            "collected 2 items                                                              \u001b[0m\n",
            "\n",
            "tests/test_core.py::test_config_init \u001b[32mPASSED\u001b[0m\u001b[32m                              [ 50%]\u001b[0m\n",
            "tests/test_core.py::test_db_create_and_log \u001b[32mPASSED\u001b[0m\u001b[32m                        [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.24s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
            "config.py  db.py  __pycache__\n",
            "loan_iq.db  reports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell to create, run, and test modules/bootstrap/deps.py, modules/core/config.py, modules/core/db.py, modules/core/utils.py, and modules/core/auth.py\n",
        "# Run this entire block in Colab to execute all steps\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "print(f\"Current working directory: {os.getcwd()}\")  # Debug\n",
        "\n",
        "# Create directories and reset database/dependencies\n",
        "!mkdir -p modules/bootstrap modules/core tests data models data/reports\n",
        "!rm -f data/loan_iq.db data/.deps_ok\n",
        "!ls modules/bootstrap || echo \"Directory modules/bootstrap created\"\n",
        "!ls modules/core || echo \"Directory modules/core created\"\n",
        "!ls data || echo \"Directory data created\"\n",
        "\n",
        "# Write deps.py using Python\n",
        "os.makedirs('modules/bootstrap', exist_ok=True)\n",
        "with open('modules/bootstrap/deps.py', 'w') as f:\n",
        "    f.write('''# modules/bootstrap/deps.py\n",
        "# Estimated line count: 50\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "REQUIRED_LIBS = [\n",
        "    'streamlit==1.38.0',\n",
        "    'pandas==2.2.2',\n",
        "    'numpy==1.26.4',\n",
        "    'scikit-learn==1.5.1',\n",
        "    'xgboost==2.1.1',\n",
        "    'plotly==5.22.0',\n",
        "    'faker==28.1.0',\n",
        "    'openpyxl==3.1.5',\n",
        "    'reportlab==4.2.2',\n",
        "    'pytest==8.3.2',\n",
        "    'shap==0.46.0'\n",
        "]\n",
        "\n",
        "def install_deps():\n",
        "    \"\"\"Install required libraries and create marker file.\"\"\"\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    marker_path = os.path.join('data', '.deps_ok')\n",
        "    if not os.path.exists(marker_path):\n",
        "        for lib in REQUIRED_LIBS:\n",
        "            try:\n",
        "                __import__(lib.split('==')[0])\n",
        "            except ImportError:\n",
        "                subprocess.check_call(['pip', 'install', lib])\n",
        "        with open(marker_path, 'w') as f:\n",
        "            f.write('OK')\n",
        "        print(\"Dependencies installed successfully.\")\n",
        "    else:\n",
        "        print(\"Dependencies already installed.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    install_deps()\n",
        "''')\n",
        "!test -f modules/bootstrap/deps.py && echo \"deps.py created\" || echo \"Failed to create deps.py\"\n",
        "\n",
        "# Write config.py using Python\n",
        "os.makedirs('modules/core', exist_ok=True)\n",
        "with open('modules/core/config.py', 'w') as f:\n",
        "    f.write('''# modules/core/config.py\n",
        "# Estimated line count: 60\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "ADMIN_CREDENTIALS = {\n",
        "    \"username\": \"admin\",\n",
        "    \"password\": \"Shady868\"\n",
        "}\n",
        "\n",
        "SEEDS = {\n",
        "    \"faker\": 42,\n",
        "    \"numpy\": 42,\n",
        "    \"random\": 42\n",
        "}\n",
        "\n",
        "CONFIG = {\n",
        "    \"data_dir\": os.path.join(\"data\"),\n",
        "    \"model_dir\": os.path.join(\"models\"),\n",
        "    \"report_dir\": os.path.join(\"data\", \"reports\"),\n",
        "    \"db_path\": os.path.join(\"data\", \"loan_iq.db\"),\n",
        "    \"drive_root\": \"/content/drive/MyDrive/loan_iq\",\n",
        "    \"streamlit_port\": 8501,\n",
        "    \"fraud_types\": [\"ghost_client\", \"duplicate_id\", \"missed_payment\", \"identity_theft\"],\n",
        "    \"regions\": [\"urban\", \"rural\", \"semi_urban\"],\n",
        "    \"max_clients_batch\": 70000,\n",
        "    \"default_batch_size\": 1000\n",
        "}\n",
        "\n",
        "def init_seeds():\n",
        "    \"\"\"Initialize random seeds for reproducibility.\"\"\"\n",
        "    random.seed(SEEDS[\"random\"])\n",
        "    np.random.seed(SEEDS[\"numpy\"])\n",
        "\n",
        "def get_config():\n",
        "    \"\"\"Return config dictionary, ensure directories exist.\"\"\"\n",
        "    os.makedirs(CONFIG[\"data_dir\"], exist_ok=True)\n",
        "    os.makedirs(CONFIG[\"model_dir\"], exist_ok=True)\n",
        "    os.makedirs(CONFIG[\"report_dir\"], exist_ok=True)\n",
        "    return CONFIG\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    init_seeds()\n",
        "    config = get_config()\n",
        "    print(f\"Config loaded: {config}\")\n",
        "''')\n",
        "!test -f modules/core/config.py && echo \"config.py created\" || echo \"Failed to create config.py\"\n",
        "\n",
        "# Write db.py using Python\n",
        "with open('modules/core/db.py', 'w') as f:\n",
        "    f.write('''# modules/core/db.py\n",
        "# Estimated line count: 120\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "import sqlite3\n",
        "import json\n",
        "from datetime import datetime, UTC\n",
        "try:\n",
        "    from modules.core import config\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class DB:\n",
        "    \"\"\"SQLite database wrapper for Loan IQ.\"\"\"\n",
        "    def __init__(self):\n",
        "        print(f\"sys.path: {sys.path}\")  # Debug path\n",
        "        self.db_path = config.get_config()[\"db_path\"]\n",
        "        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n",
        "        print(f\"Creating database at: {self.db_path}\")  # Debug\n",
        "        self.conn = sqlite3.connect(self.db_path)\n",
        "        self.conn.row_factory = sqlite3.Row  # Enable dict-like row access\n",
        "        self.cursor = self.conn.cursor()\n",
        "        self.create_tables()\n",
        "        print(f\"Database created: {os.path.exists(self.db_path)}\")  # Debug\n",
        "\n",
        "    def create_tables(self):\n",
        "        \"\"\"Create database tables.\"\"\"\n",
        "        tables = [\n",
        "            \"CREATE TABLE IF NOT EXISTS users (user_id TEXT PRIMARY KEY, username TEXT UNIQUE, password TEXT, role TEXT)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS clients (client_id TEXT PRIMARY KEY, name TEXT, branch TEXT, region TEXT, income REAL, created_at TIMESTAMP)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS loans (loan_id TEXT PRIMARY KEY, client_id TEXT, amount REAL, status TEXT, start_date TIMESTAMP, FOREIGN KEY (client_id) REFERENCES clients(client_id))\",\n",
        "            \"CREATE TABLE IF NOT EXISTS transactions (transaction_id TEXT PRIMARY KEY, loan_id TEXT, amount REAL, date TIMESTAMP, type TEXT, FOREIGN KEY (loan_id) REFERENCES loans(loan_id))\",\n",
        "            \"CREATE TABLE IF NOT EXISTS models (model_id TEXT PRIMARY KEY, type TEXT, version TEXT, created_at TIMESTAMP)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS model_versions (version_id TEXT PRIMARY KEY, model_id TEXT, config_json TEXT, data_hash TEXT, metrics_json TEXT, commit_ref TEXT, comments TEXT, created_at TIMESTAMP, FOREIGN KEY (model_id) REFERENCES models(model_id))\",\n",
        "            \"CREATE TABLE IF NOT EXISTS audit_logs (log_id INTEGER PRIMARY KEY AUTOINCREMENT, actor_id TEXT, actor_role TEXT, action TEXT, target_id TEXT, target_type TEXT, reason TEXT, timestamp TIMESTAMP, before_snapshot TEXT, after_snapshot TEXT, reversible BOOLEAN, reversal_id INTEGER)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS simulations (sim_id TEXT PRIMARY KEY, user_id TEXT, params_json TEXT, created_at TIMESTAMP)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS reports (report_id TEXT PRIMARY KEY, type TEXT, path TEXT, created_at TIMESTAMP)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS assets (asset_id TEXT PRIMARY KEY, path TEXT, type TEXT, created_at TIMESTAMP)\"\n",
        "        ]\n",
        "        for table_sql in tables:\n",
        "            self.cursor.execute(table_sql)\n",
        "        self.conn.commit()\n",
        "\n",
        "    def log_action(self, actor_id, actor_role, action, target_id, target_type, reason, before_snapshot, after_snapshot, reversible=False):\n",
        "        \"\"\"Log an admin action to audit_logs.\"\"\"\n",
        "        timestamp = datetime.now(UTC).isoformat()\n",
        "        snapshot_before = json.dumps(before_snapshot) if before_snapshot else \"\"\n",
        "        snapshot_after = json.dumps(after_snapshot) if after_snapshot else \"\"\n",
        "        self.cursor.execute(\n",
        "            \"INSERT INTO audit_logs (actor_id, actor_role, action, target_id, target_type, reason, timestamp, before_snapshot, after_snapshot, reversible) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "            (actor_id, actor_role, action, target_id, target_type, reason, timestamp, snapshot_before, snapshot_after, reversible)\n",
        "        )\n",
        "        self.conn.commit()\n",
        "        return self.cursor.lastrowid\n",
        "\n",
        "    def get_audit_trail(self, target_id=None, target_type=None):\n",
        "        \"\"\"Retrieve audit logs, optionally filtered.\"\"\"\n",
        "        query = \"SELECT * FROM audit_logs\"\n",
        "        params = []\n",
        "        if target_id and target_type:\n",
        "            query += \" WHERE target_id = ? AND target_type = ?\"\n",
        "            params = [target_id, target_type]\n",
        "        self.cursor.execute(query, params)\n",
        "        return self.cursor.fetchall()\n",
        "\n",
        "    def rollback_action(self, action_id):\n",
        "        \"\"\"Attempt to rollback an action if reversible.\"\"\"\n",
        "        self.cursor.execute(\"SELECT reversible, before_snapshot, target_id, target_type, action FROM audit_logs WHERE log_id = ?\", (action_id,))\n",
        "        result = self.cursor.fetchone()\n",
        "        if not result or not result[0]:\n",
        "            return False\n",
        "        before_snapshot = json.loads(result[1]) if result[1] else {}\n",
        "        target_id, target_type, action = result[2], result[3], result[4]\n",
        "        if target_type == \"user\" and action == \"edit\":\n",
        "            self.cursor.execute(\"UPDATE users SET username = ?, password = ?, role = ? WHERE user_id = ?\",\n",
        "                              (before_snapshot.get(\"username\"), before_snapshot.get(\"password\"), before_snapshot.get(\"role\"), target_id))\n",
        "            self.conn.commit()\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Close database connection.\"\"\"\n",
        "        self.conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    db = DB()\n",
        "    db.cursor.execute(\"INSERT OR IGNORE INTO users (user_id, username, password, role) VALUES (?, ?, ?, ?)\",\n",
        "                     (\"1\", \"admin\", \"Shady868\", \"admin\"))\n",
        "    db.conn.commit()\n",
        "    db.log_action(\"1\", \"admin\", \"init\", \"1\", \"user\", \"Initialize admin user\", {}, {\"username\": \"admin\"})\n",
        "    print(\"Database initialized.\")\n",
        "    db.close()\n",
        "''')\n",
        "!test -f modules/core/db.py && echo \"db.py created\" || echo \"Failed to create db.py\"\n",
        "\n",
        "# Write utils.py using Python\n",
        "with open('modules/core/utils.py', 'w') as f:\n",
        "    f.write('''# modules/core/utils.py\n",
        "# Estimated line count: 80\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "import json\n",
        "from functools import wraps\n",
        "try:\n",
        "    from modules.core import db, config\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "def audit_wrapper(func):\n",
        "    \"\"\"Decorator to log admin actions with snapshots and reason.\"\"\"\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, actor_id, actor_role, reason, **kwargs):\n",
        "        if not reason:\n",
        "            raise ValueError(\"Reason is required for audited actions\")\n",
        "        database = db.DB()\n",
        "        target_id = kwargs.get('target_id', args[0] if args else 'unknown')\n",
        "        target_type = kwargs.get('target_type', func.__name__)\n",
        "        before_snapshot = {}\n",
        "        try:\n",
        "            if target_type in ['user', 'edit_user', 'delete_user', 'add_user']:\n",
        "                database.cursor.execute(\"SELECT * FROM users WHERE user_id = ?\", (target_id,))\n",
        "                row = database.cursor.fetchone()\n",
        "                before_snapshot = dict(row) if row else {}\n",
        "                print(f\"Before snapshot: {before_snapshot}\")  # Debug\n",
        "            filtered_kwargs = {k: v for k, v in kwargs.items() if k != 'target_type'}\n",
        "            result = func(*args, actor_id=actor_id, actor_role=actor_role, reason=reason, **filtered_kwargs)\n",
        "            after_snapshot = {}\n",
        "            if target_type in ['user', 'edit_user', 'delete_user', 'add_user']:\n",
        "                database.cursor.execute(\"SELECT * FROM users WHERE user_id = ?\", (target_id,))\n",
        "                row = database.cursor.fetchone()\n",
        "                after_snapshot = dict(row) if row else {}\n",
        "                print(f\"After snapshot: {after_snapshot}\")  # Debug\n",
        "            reversible = target_type in ['user', 'edit_user', 'add_user']\n",
        "            log_id = database.log_action(\n",
        "                actor_id, actor_role, func.__name__, target_id, target_type, reason,\n",
        "                before_snapshot, after_snapshot, reversible\n",
        "            )\n",
        "            database.close()\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            database.close()\n",
        "            raise Exception(f\"Action failed: {e}\")\n",
        "    return wrapper\n",
        "\n",
        "def dict_diff(before, after):\n",
        "    \"\"\"Compute difference between two dictionaries for audit logging.\"\"\"\n",
        "    diff = {}\n",
        "    for key in set(before.keys()) | set(after.keys()):\n",
        "        if before.get(key) != after.get(key):\n",
        "            diff[key] = {'before': before.get(key), 'after': after.get(key)}\n",
        "    return diff\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    @audit_wrapper\n",
        "    def test_action(target_id, actor_id, actor_role, reason):\n",
        "        return {\"result\": \"test\"}\n",
        "    result = test_action(\"test_id\", actor_id=\"1\", actor_role=\"admin\", reason=\"Test audit\")\n",
        "    print(f\"Test action result: {result}\")\n",
        "''')\n",
        "!test -f modules/core/utils.py && echo \"utils.py created\" || echo \"Failed to create utils.py\"\n",
        "\n",
        "# Write auth.py using Python\n",
        "with open('modules/core/auth.py', 'w') as f:\n",
        "    f.write('''# modules/core/auth.py\n",
        "# Estimated line count: 80\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "import sqlite3\n",
        "try:\n",
        "    from modules.core import config, db, utils\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "def authenticate(username, password):\n",
        "    \"\"\"Authenticate user against stored credentials.\"\"\"\n",
        "    cfg = config.get_config()\n",
        "    if username == config.ADMIN_CREDENTIALS[\"username\"] and password == config.ADMIN_CREDENTIALS[\"password\"]:\n",
        "        return {\"user_id\": \"1\", \"role\": \"admin\"}\n",
        "    database = db.DB()\n",
        "    database.cursor.execute(\"SELECT user_id, role FROM users WHERE username = ? AND password = ?\", (username, password))\n",
        "    user = database.cursor.fetchone()\n",
        "    database.close()\n",
        "    if user:\n",
        "        return {\"user_id\": user[0], \"role\": user[1]}\n",
        "    return None\n",
        "\n",
        "@utils.audit_wrapper\n",
        "def add_user(username, password, role, actor_id, actor_role, reason, target_id=None):\n",
        "    \"\"\"Add a new user with audit logging.\"\"\"\n",
        "    target_id = target_id or f\"u_{str(hash(username))[:8]}\"\n",
        "    print(f\"Adding user with target_id: {target_id}\")  # Debug\n",
        "    database = db.DB()\n",
        "    try:\n",
        "        database.cursor.execute(\"INSERT INTO users (user_id, username, password, role) VALUES (?, ?, ?, ?)\",\n",
        "                              (target_id, username, password, role))\n",
        "        database.conn.commit()\n",
        "        database.close()\n",
        "        return target_id\n",
        "    except sqlite3.IntegrityError as e:\n",
        "        database.close()\n",
        "        raise ValueError(f\"Failed to add user {username}: {e}\")\n",
        "\n",
        "@utils.audit_wrapper\n",
        "def edit_user(user_id, updates, actor_id, actor_role, reason, target_id=None):\n",
        "    \"\"\"Edit user details with audit logging.\"\"\"\n",
        "    target_id = target_id or user_id\n",
        "    database = db.DB()\n",
        "    allowed_fields = ['username', 'password', 'role']\n",
        "    updates = {k: v for k, v in updates.items() if k in allowed_fields}\n",
        "    if not updates:\n",
        "        database.close()\n",
        "        raise ValueError(\"No valid fields to update\")\n",
        "    set_clause = \", \".join(f\"{k} = ?\" for k in updates.keys())\n",
        "    values = list(updates.values()) + [user_id]\n",
        "    try:\n",
        "        database.cursor.execute(f\"UPDATE users SET {set_clause} WHERE user_id = ?\", values)\n",
        "        database.conn.commit()\n",
        "        database.close()\n",
        "        return True\n",
        "    except sqlite3.IntegrityError as e:\n",
        "        database.close()\n",
        "        raise ValueError(f\"Failed to edit user {user_id}: {e}\")\n",
        "\n",
        "@utils.audit_wrapper\n",
        "def delete_user(user_id, actor_id, actor_role, reason, target_id=None, confirmation=None):\n",
        "    \"\"\"Delete user with audit logging and confirmation.\"\"\"\n",
        "    target_id = target_id or user_id\n",
        "    if confirmation != f\"CONFIRM DELETE {user_id}\":\n",
        "        raise ValueError(\"Invalid confirmation for deletion\")\n",
        "    database = db.DB()\n",
        "    try:\n",
        "        database.cursor.execute(\"DELETE FROM users WHERE user_id = ?\", (user_id,))\n",
        "        database.conn.commit()\n",
        "        database.close()\n",
        "        return True\n",
        "    except sqlite3.Error as e:\n",
        "        database.close()\n",
        "        raise ValueError(f\"Failed to delete user {user_id}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user = authenticate(\"admin\", \"Shady868\")\n",
        "    print(f\"Auth result: {user}\")\n",
        "    try:\n",
        "        new_user_id = add_user(\"test_user\", \"test_pass\", \"user\", actor_id=\"1\", actor_role=\"admin\", reason=\"Test add user\", target_id=\"test_1\")\n",
        "        print(f\"Added user: {new_user_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error adding user: {e}\")\n",
        "''')\n",
        "!test -f modules/core/auth.py && echo \"auth.py created\" || echo \"Failed to create auth.py\"\n",
        "\n",
        "# Write test_core.py using Python\n",
        "os.makedirs('tests', exist_ok=True)\n",
        "with open('tests/test_core.py', 'w') as f:\n",
        "    f.write('''# tests/test_core.py\n",
        "# Estimated line count: 60\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import sqlite3\n",
        "sys.path.append(os.getcwd())\n",
        "try:\n",
        "    from modules.core import config, db, utils, auth\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "def test_config_init():\n",
        "    cfg = config.get_config()\n",
        "    assert os.path.exists(cfg[\"data_dir\"]), \"Data directory not created\"\n",
        "    assert cfg[\"streamlit_port\"] == 8501, \"Incorrect port\"\n",
        "    assert config.ADMIN_CREDENTIALS[\"username\"] == \"admin\", \"Admin username incorrect\"\n",
        "\n",
        "def test_db_create_and_log():\n",
        "    database = db.DB()\n",
        "    database.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='audit_logs'\")\n",
        "    assert database.cursor.fetchone(), \"Audit logs table not created\"\n",
        "    log_id = database.log_action(\"1\", \"admin\", \"test_action\", \"test_id\", \"test_type\", \"Test reason\", {\"key\": \"before\"}, {\"key\": \"after\"}, True)\n",
        "    assert log_id, \"Failed to log action\"\n",
        "    audit_logs = database.get_audit_trail(\"test_id\", \"test_type\")\n",
        "    assert len(audit_logs) > 0, \"Audit log not recorded\"\n",
        "    database.close()\n",
        "\n",
        "def test_authenticate():\n",
        "    user = auth.authenticate(\"admin\", \"Shady868\")\n",
        "    assert user == {\"user_id\": \"1\", \"role\": \"admin\"}, \"Admin authentication failed\"\n",
        "    user = auth.authenticate(\"wrong\", \"wrong\")\n",
        "    assert user is None, \"Invalid credentials should fail\"\n",
        "\n",
        "def test_audit_wrapper():\n",
        "    @utils.audit_wrapper\n",
        "    def test_action(target_id, actor_id, actor_role, reason):\n",
        "        return True\n",
        "    result = test_action(\"test_id\", actor_id=\"1\", actor_role=\"admin\", reason=\"Test audit\")\n",
        "    assert result, \"Audit wrapper failed\"\n",
        "    database = db.DB()\n",
        "    logs = database.get_audit_trail(\"test_id\", \"test_action\")\n",
        "    assert len(logs) > 0, \"Audit log not recorded\"\n",
        "    database.close()\n",
        "\n",
        "def test_add_user():\n",
        "    database = db.DB()\n",
        "    database.cursor.execute(\"DELETE FROM users WHERE user_id = ?\", (\"test_2\",))\n",
        "    database.conn.commit()\n",
        "    database.close()\n",
        "    user_id = auth.add_user(\"test_user2\", \"test_pass2\", \"user\", actor_id=\"1\", actor_role=\"admin\", reason=\"Test add user\", target_id=\"test_2\")\n",
        "    assert user_id == \"test_2\", \"Failed to add user\"\n",
        "    database = db.DB()\n",
        "    database.cursor.execute(\"SELECT username FROM users WHERE user_id = ?\", (\"test_2\",))\n",
        "    result = database.cursor.fetchone()\n",
        "    assert result and result[0] == \"test_user2\", \"User not added correctly\"\n",
        "    database.close()\n",
        "\n",
        "def test_edit_user():\n",
        "    database = db.DB()\n",
        "    database.cursor.execute(\"DELETE FROM users WHERE user_id = ?\", (\"test_2\",))\n",
        "    database.cursor.execute(\"INSERT INTO users (user_id, username, password, role) VALUES (?, ?, ?, ?)\",\n",
        "                          (\"test_2\", \"test_user2\", \"test_pass2\", \"user\"))\n",
        "    database.conn.commit()\n",
        "    database.close()\n",
        "    result = auth.edit_user(\"test_2\", {\"password\": \"new_pass\"}, actor_id=\"1\", actor_role=\"admin\", reason=\"Test edit user\", target_id=\"test_2\")\n",
        "    assert result, \"Failed to edit user\"\n",
        "    database = db.DB()\n",
        "    database.cursor.execute(\"SELECT password FROM users WHERE user_id = ?\", (\"test_2\",))\n",
        "    result = database.cursor.fetchone()\n",
        "    assert result and result[0] == \"new_pass\", \"User not edited correctly\"\n",
        "    database.close()\n",
        "\n",
        "def test_db_existence():\n",
        "    assert os.path.exists(\"data/loan_iq.db\"), \"Database file not created\"\n",
        "''')\n",
        "!test -f tests/test_core.py && echo \"test_core.py created\" || echo \"Failed to create test_core.py\"\n",
        "\n",
        "# Ensure dependencies are installed\n",
        "!python modules/bootstrap/deps.py\n",
        "\n",
        "# Verify directories\n",
        "!ls modules/bootstrap || echo \"modules/bootstrap not found\"\n",
        "!ls modules/core || echo \"modules/core not found\"\n",
        "!ls data || echo \"data not found\"\n",
        "\n",
        "# Run config.py\n",
        "!python modules/core/config.py\n",
        "\n",
        "# Run db.py\n",
        "!python modules/core/db.py\n",
        "\n",
        "# Run utils.py\n",
        "!python modules/core/utils.py\n",
        "\n",
        "# Run auth.py\n",
        "!python modules/core/auth.py\n",
        "\n",
        "# Run tests\n",
        "!pytest tests/test_core.py -v\n",
        "\n",
        "# Verify files\n",
        "!ls modules/bootstrap\n",
        "!ls modules/core\n",
        "!ls data\n",
        "\n",
        "# Expected output:\n",
        "# Current working directory: /content\n",
        "# Directory modules/bootstrap created\n",
        "# Directory modules/core created\n",
        "# Directory data created\n",
        "# deps.py created\n",
        "# config.py created\n",
        "# db.py created\n",
        "# utils.py created\n",
        "# auth.py created\n",
        "# test_core.py created\n",
        "# Dependencies installed successfully.\n",
        "# deps.py\n",
        "# auth.py  config.py  db.py  utils.py\n",
        "# .deps_ok  loan_iq.db  reports\n",
        "# Config loaded: {'data_dir': 'data', 'model_dir': 'models', 'report_dir': 'data/reports', 'db_path': 'data/loan_iq.db', 'drive_root': '/content/drive/MyDrive/loan_iq', 'streamlit_port': 8501, 'fraud_types': ['ghost_client', 'duplicate_"
      ],
      "metadata": {
        "id": "jQ-DFEWxznU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d655bcf5-8de2-4ede-ff92-be41c01dd15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "deps.py\n",
            "auth.py  config.py  db.py  __pycache__\tutils.py\n",
            "reports\n",
            "deps.py created\n",
            "config.py created\n",
            "db.py created\n",
            "utils.py created\n",
            "auth.py created\n",
            "test_core.py created\n",
            "Requirement already satisfied: scikit-learn==1.5.1 in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.1) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.1) (3.6.0)\n",
            "Dependencies installed successfully.\n",
            "deps.py\n",
            "auth.py  config.py  db.py  __pycache__\tutils.py\n",
            "reports\n",
            "Config loaded: {'data_dir': 'data', 'model_dir': 'models', 'report_dir': 'data/reports', 'db_path': 'data/loan_iq.db', 'drive_root': '/content/drive/MyDrive/loan_iq', 'streamlit_port': 8501, 'fraud_types': ['ghost_client', 'duplicate_id', 'missed_payment', 'identity_theft'], 'regions': ['urban', 'rural', 'semi_urban'], 'max_clients_batch': 70000, 'default_batch_size': 1000}\n",
            "sys.path: ['/content/modules/core', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Database initialized.\n",
            "sys.path: ['/content/modules/core', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Test action result: {'result': 'test'}\n",
            "Auth result: {'user_id': '1', 'role': 'admin'}\n",
            "sys.path: ['/content/modules/core', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Before snapshot: {}\n",
            "Adding user with target_id: test_1\n",
            "sys.path: ['/content/modules/core', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "After snapshot: {'user_id': 'test_1', 'username': 'test_user', 'password': 'test_pass', 'role': 'user'}\n",
            "Added user: test_1\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: Faker-28.1.0, anyio-4.10.0, typeguard-4.4.4, langsmith-0.4.16\n",
            "collected 7 items                                                              \u001b[0m\n",
            "\n",
            "tests/test_core.py::test_config_init \u001b[32mPASSED\u001b[0m\u001b[32m                              [ 14%]\u001b[0m\n",
            "tests/test_core.py::test_db_create_and_log \u001b[32mPASSED\u001b[0m\u001b[32m                        [ 28%]\u001b[0m\n",
            "tests/test_core.py::test_authenticate \u001b[32mPASSED\u001b[0m\u001b[32m                             [ 42%]\u001b[0m\n",
            "tests/test_core.py::test_audit_wrapper \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 57%]\u001b[0m\n",
            "tests/test_core.py::test_add_user \u001b[32mPASSED\u001b[0m\u001b[32m                                 [ 71%]\u001b[0m\n",
            "tests/test_core.py::test_edit_user \u001b[32mPASSED\u001b[0m\u001b[32m                                [ 85%]\u001b[0m\n",
            "tests/test_core.py::test_db_existence \u001b[32mPASSED\u001b[0m\u001b[32m                             [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m7 passed\u001b[0m\u001b[32m in 0.26s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
            "deps.py\n",
            "auth.py  config.py  db.py  __pycache__\tutils.py\n",
            "loan_iq.db  reports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell to create, run, and test modules/synth/faker_engine.py and modules/synth/generators.py\n",
        "# Run this entire block in Colab to execute all steps\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "print(f\"Current working directory: {os.getcwd()}\")  # Debug\n",
        "\n",
        "# Create directories and reset database to prevent schema conflicts\n",
        "!mkdir -p modules/synth tests data models data/reports\n",
        "!rm -f data/loan_iq.db\n",
        "!ls modules/synth || echo \"Directory modules/synth created\"\n",
        "!ls tests || echo \"Directory tests created\"\n",
        "!ls data || echo \"Directory data created\"\n",
        "\n",
        "# Write faker_engine.py using Python\n",
        "os.makedirs('modules/synth', exist_ok=True)\n",
        "with open('modules/synth/faker_engine.py', 'w') as f:\n",
        "    f.write('''# modules/synth/faker_engine.py\n",
        "# Estimated line count: 300\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "try:\n",
        "    from modules.core import config\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class LoanIQFaker:\n",
        "    \"\"\"Custom Faker for generating Loan IQ synthetic data with fraud patterns.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.faker = Faker()\n",
        "        Faker.seed(config.SEEDS[\"faker\"])\n",
        "        random.seed(config.SEEDS[\"random\"])\n",
        "        self.config = config.get_config()\n",
        "        self.fraud_types = self.config[\"fraud_types\"]\n",
        "        self.regions = self.config[\"regions\"]\n",
        "\n",
        "    def client_id(self):\n",
        "        \"\"\"Generate unique client ID.\"\"\"\n",
        "        return f\"C_{self.faker.uuid4().split('-')[0]}\"\n",
        "\n",
        "    def loan_id(self):\n",
        "        \"\"\"Generate unique loan ID.\"\"\"\n",
        "        return f\"L_{self.faker.uuid4().split('-')[0]}\"\n",
        "\n",
        "    def transaction_id(self):\n",
        "        \"\"\"Generate unique transaction ID.\"\"\"\n",
        "        return f\"T_{self.faker.uuid4().split('-')[0]}\"\n",
        "\n",
        "    def client_name(self, fraud_type=None):\n",
        "        \"\"\"Generate client name, with ghost client fraud option.\"\"\"\n",
        "        if fraud_type == \"ghost_client\" and random.random() < 0.1:\n",
        "            return None  # Ghost client has no name\n",
        "        return self.faker.name()\n",
        "\n",
        "    def duplicate_id(self, existing_ids):\n",
        "        \"\"\"Generate client ID with chance of duplication for fraud.\"\"\"\n",
        "        if random.random() < 0.05:  # 5% chance of duplicate ID\n",
        "            return random.choice(existing_ids) if existing_ids else self.client_id()\n",
        "        return self.client_id()\n",
        "\n",
        "    def income(self, fraud_type=None):\n",
        "        \"\"\"Generate income, with variance for fraud.\"\"\"\n",
        "        if fraud_type == \"identity_theft\" and random.random() < 0.1:\n",
        "            return random.uniform(100000, 1000000)  # Suspiciously high income\n",
        "        return random.uniform(20000, 100000)\n",
        "\n",
        "    def branch(self):\n",
        "        \"\"\"Generate branch name.\"\"\"\n",
        "        return self.faker.city()\n",
        "\n",
        "    def region(self):\n",
        "        \"\"\"Generate region from config.\"\"\"\n",
        "        return random.choice(self.regions)\n",
        "\n",
        "    def loan_amount(self, fraud_type=None):\n",
        "        \"\"\"Generate loan amount, with variance for fraud.\"\"\"\n",
        "        if fraud_type == \"missed_payment\" and random.random() < 0.2:\n",
        "            return random.uniform(50000, 200000)  # Higher loan for missed payments\n",
        "        return random.uniform(1000, 50000)\n",
        "\n",
        "    def loan_status(self, fraud_type=None):\n",
        "        \"\"\"Generate loan status, with fraud influence.\"\"\"\n",
        "        statuses = [\"active\", \"paid\", \"default\"]\n",
        "        if fraud_type == \"missed_payment\" and random.random() < 0.3:\n",
        "            return \"default\"\n",
        "        return random.choice(statuses)\n",
        "\n",
        "    def transaction_amount(self, loan_amount):\n",
        "        \"\"\"Generate transaction amount based on loan.\"\"\"\n",
        "        return random.uniform(100, min(loan_amount * 0.1, 5000))\n",
        "\n",
        "    def transaction_type(self, fraud_type=None):\n",
        "        \"\"\"Generate transaction type, with fraud influence.\"\"\"\n",
        "        types = [\"payment\", \"fee\", \"interest\"]\n",
        "        if fraud_type == \"identity_theft\" and random.random() < 0.1:\n",
        "            return \"suspicious_transfer\"\n",
        "        return random.choice(types)\n",
        "\n",
        "    def random_date(self, start_days=-365, end_days=0):\n",
        "        \"\"\"Generate random date within range.\"\"\"\n",
        "        start = datetime.now() + timedelta(days=start_days)\n",
        "        end = datetime.now() + timedelta(days=end_days)\n",
        "        return self.faker.date_time_between(start, end).isoformat()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    faker = LoanIQFaker()\n",
        "    print(f\"Client ID: {faker.client_id()}\")\n",
        "    print(f\"Client Name: {faker.client_name()}\")\n",
        "    print(f\"Loan ID: {faker.loan_id()}\")\n",
        "    print(f\"Transaction ID: {faker.transaction_id()}\")\n",
        "    print(f\"Income: {faker.income()}\")\n",
        "    print(f\"Branch: {faker.branch()}\")\n",
        "    print(f\"Region: {faker.region()}\")\n",
        "    print(f\"Loan Amount: {faker.loan_amount()}\")\n",
        "    print(f\"Loan Status: {faker.loan_status()}\")\n",
        "    print(f\"Transaction Amount: {faker.transaction_amount(10000)}\")\n",
        "    print(f\"Transaction Type: {faker.transaction_type()}\")\n",
        "    print(f\"Random Date: {faker.random_date()}\")\n",
        "''')\n",
        "!test -f modules/synth/faker_engine.py && echo \"faker_engine.py created\" || echo \"Failed to create faker_engine.py\"\n",
        "\n",
        "# Write generators.py using Python\n",
        "with open('modules/synth/generators.py', 'w') as f:\n",
        "    f.write('''# modules/synth/generators.py\n",
        "# Estimated line count: 250\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "sys.path.append(os.getcwd())\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "try:\n",
        "    from modules.core import db, config\n",
        "    from modules.synth import faker_engine\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class DataGenerator:\n",
        "    \"\"\"Generate synthetic data for Loan IQ and store in database.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.faker = faker_engine.LoanIQFaker()\n",
        "        self.config = config.get_config()\n",
        "        self.db_path = self.config[\"db_path\"]\n",
        "\n",
        "    def generate_clients(self, n, fraud_ratio=0.1):\n",
        "        \"\"\"Generate n clients with optional fraud patterns.\"\"\"\n",
        "        clients = []\n",
        "        existing_ids = []\n",
        "        for _ in range(n):\n",
        "            fraud_type = random.choices(\n",
        "                self.faker.fraud_types + [None],\n",
        "                weights=[fraud_ratio / len(self.faker.fraud_types)] * len(self.faker.fraud_types) + [1 - fraud_ratio],\n",
        "                k=1\n",
        "            )[0]\n",
        "            client_id = self.faker.duplicate_id(existing_ids) if fraud_type == \"duplicate_id\" else self.faker.client_id()\n",
        "            existing_ids.append(client_id)\n",
        "            clients.append({\n",
        "                \"client_id\": client_id,\n",
        "                \"name\": self.faker.client_name(fraud_type),\n",
        "                \"branch\": self.faker.branch(),\n",
        "                \"region\": self.faker.region(),\n",
        "                \"income\": self.faker.income(fraud_type),\n",
        "                \"created_at\": self.faker.random_date()\n",
        "            })\n",
        "        return pd.DataFrame(clients)\n",
        "\n",
        "    def generate_loans(self, clients, n_per_client=2, fraud_ratio=0.1):\n",
        "        \"\"\"Generate loans for given clients.\"\"\"\n",
        "        loans = []\n",
        "        for client_id in clients[\"client_id\"]:\n",
        "            fraud_type = random.choices(\n",
        "                self.faker.fraud_types + [None],\n",
        "                weights=[fraud_ratio / len(self.faker.fraud_types)] * len(self.faker.fraud_types) + [1 - fraud_ratio],\n",
        "                k=1\n",
        "            )[0]\n",
        "            for _ in range(random.randint(1, n_per_client)):\n",
        "                loans.append({\n",
        "                    \"loan_id\": self.faker.loan_id(),\n",
        "                    \"client_id\": client_id,\n",
        "                    \"amount\": self.faker.loan_amount(fraud_type),\n",
        "                    \"status\": self.faker.loan_status(fraud_type),\n",
        "                    \"start_date\": self.faker.random_date()\n",
        "                })\n",
        "        return pd.DataFrame(loans)\n",
        "\n",
        "    def generate_transactions(self, loans, n_per_loan=3, fraud_ratio=0.1):\n",
        "        \"\"\"Generate transactions for given loans.\"\"\"\n",
        "        transactions = []\n",
        "        for loan_id, loan_amount in zip(loans[\"loan_id\"], loans[\"amount\"]):\n",
        "            fraud_type = random.choices(\n",
        "                self.faker.fraud_types + [None],\n",
        "                weights=[fraud_ratio / len(self.faker.fraud_types)] * len(self.faker.fraud_types) + [1 - fraud_ratio],\n",
        "                k=1\n",
        "            )[0]\n",
        "            for _ in range(random.randint(1, n_per_loan)):\n",
        "                transactions.append({\n",
        "                    \"transaction_id\": self.faker.transaction_id(),\n",
        "                    \"loan_id\": loan_id,\n",
        "                    \"amount\": self.faker.transaction_amount(loan_amount),\n",
        "                    \"date\": self.faker.random_date(),\n",
        "                    \"type\": self.faker.transaction_type(fraud_type)\n",
        "                })\n",
        "        return pd.DataFrame(transactions)\n",
        "\n",
        "    def save_to_db(self, clients, loans, transactions, actor_id=\"1\", actor_role=\"admin\", reason=\"Synthetic data generation\"):\n",
        "        \"\"\"Save generated data to loan_iq.db with audit logging.\"\"\"\n",
        "        database = db.DB()\n",
        "        print(f\"Saving to database: {self.db_path}\")  # Debug\n",
        "        try:\n",
        "            # Save clients\n",
        "            for _, row in clients.iterrows():\n",
        "                database.cursor.execute(\n",
        "                    \"INSERT OR IGNORE INTO clients (client_id, name, branch, region, income, created_at) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "                    (row[\"client_id\"], row[\"name\"], row[\"branch\"], row[\"region\"], row[\"income\"], row[\"created_at\"])\n",
        "                )\n",
        "            # Save loans\n",
        "            for _, row in loans.iterrows():\n",
        "                database.cursor.execute(\n",
        "                    \"INSERT OR IGNORE INTO loans (loan_id, client_id, amount, status, start_date) VALUES (?, ?, ?, ?, ?)\",\n",
        "                    (row[\"loan_id\"], row[\"client_id\"], row[\"amount\"], row[\"status\"], row[\"start_date\"])\n",
        "                )\n",
        "            # Save transactions\n",
        "            for _, row in transactions.iterrows():\n",
        "                database.cursor.execute(\n",
        "                    \"INSERT OR IGNORE INTO transactions (transaction_id, loan_id, amount, date, type) VALUES (?, ?, ?, ?, ?)\",\n",
        "                    (row[\"transaction_id\"], row[\"loan_id\"], row[\"amount\"], row[\"date\"], row[\"type\"])\n",
        "                )\n",
        "            database.conn.commit()\n",
        "            database.log_action(\n",
        "                actor_id, actor_role, \"generate_data\", \"multiple\", \"synthetic_data\", reason,\n",
        "                {}, {\"clients\": len(clients), \"loans\": len(loans), \"transactions\": len(transactions)}\n",
        "            )\n",
        "            print(f\"Saved {len(clients)} clients, {len(loans)} loans, {len(transactions)} transactions to DB\")\n",
        "        finally:\n",
        "            database.close()\n",
        "\n",
        "    def export_to_csv(self, clients, loans, transactions, output_dir=None):\n",
        "        \"\"\"Export data to CSV files.\"\"\"\n",
        "        output_dir = output_dir or self.config[\"data_dir\"]\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        clients.to_csv(os.path.join(output_dir, \"clients.csv\"), index=False)\n",
        "        loans.to_csv(os.path.join(output_dir, \"loans.csv\"), index=False)\n",
        "        transactions.to_csv(os.path.join(output_dir, \"transactions.csv\"), index=False)\n",
        "        print(f\"Exported data to {output_dir}/[clients,loans,transactions].csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generator = DataGenerator()\n",
        "    clients = generator.generate_clients(10, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    generator.save_to_db(clients, loans, transactions)\n",
        "    generator.export_to_csv(clients, loans, transactions)\n",
        "    print(\"Generated and saved synthetic data.\")\n",
        "''')\n",
        "!test -f modules/synth/generators.py && echo \"generators.py created\" || echo \"Failed to create generators.py\"\n",
        "\n",
        "# Write test_synth.py using Python\n",
        "with open('tests/test_synth.py', 'w') as f:\n",
        "    f.write('''# tests/test_synth.py\n",
        "# Estimated line count: 80\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "sys.path.append(os.getcwd())\n",
        "try:\n",
        "    from modules.core import config, db\n",
        "    from modules.synth import faker_engine, generators\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "def test_faker_engine():\n",
        "    faker = faker_engine.LoanIQFaker()\n",
        "    assert len(faker.client_id()) > 0, \"Client ID not generated\"\n",
        "    assert faker.region() in config.get_config()[\"regions\"], \"Invalid region\"\n",
        "    assert isinstance(faker.income(), float), \"Income not float\"\n",
        "    assert isinstance(faker.loan_amount(), float), \"Loan amount not float\"\n",
        "    assert faker.loan_status() in [\"active\", \"paid\", \"default\"], \"Invalid loan status\"\n",
        "\n",
        "def test_generate_clients():\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(5, fraud_ratio=0.2)\n",
        "    assert len(clients) == 5, \"Incorrect number of clients\"\n",
        "    assert set(clients.columns) == {\"client_id\", \"name\", \"branch\", \"region\", \"income\", \"created_at\"}, \"Incorrect client columns\"\n",
        "    assert clients[\"region\"].isin(config.get_config()[\"regions\"]).all(), \"Invalid regions\"\n",
        "\n",
        "def test_generate_loans():\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(3, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    assert len(loans) >= 3, \"Incorrect number of loans\"\n",
        "    assert set(loans.columns) == {\"loan_id\", \"client_id\", \"amount\", \"status\", \"start_date\"}, \"Incorrect loan columns\"\n",
        "    assert loans[\"client_id\"].isin(clients[\"client_id\"]).all(), \"Invalid client IDs in loans\"\n",
        "\n",
        "def test_generate_transactions():\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(2, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    assert len(transactions) >= 2, \"Incorrect number of transactions\"\n",
        "    assert set(transactions.columns) == {\"transaction_id\", \"loan_id\", \"amount\", \"date\", \"type\"}, \"Incorrect transaction columns\"\n",
        "    assert transactions[\"loan_id\"].isin(loans[\"loan_id\"]).all(), \"Invalid loan IDs in transactions\"\n",
        "\n",
        "def test_save_to_db():\n",
        "    generator = generators.DataGenerator()\n",
        "    database = db.DB()\n",
        "    print(f\"Clearing tables for test\")  # Debug\n",
        "    database.cursor.execute(\"DELETE FROM clients\")\n",
        "    database.cursor.execute(\"DELETE FROM loans\")\n",
        "    database.cursor.execute(\"DELETE FROM transactions\")\n",
        "    database.conn.commit()\n",
        "    database.close()\n",
        "    clients = generator.generate_clients(5, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    generator.save_to_db(clients, loans, transactions)\n",
        "    database = db.DB()\n",
        "    database.cursor.execute(\"SELECT COUNT(*) FROM clients\")\n",
        "    assert database.cursor.fetchone()[0] == 5, \"Clients not saved to DB\"\n",
        "    database.cursor.execute(\"SELECT COUNT(*) FROM loans\")\n",
        "    assert database.cursor.fetchone()[0] >= 5, \"Loans not saved to DB\"\n",
        "    database.cursor.execute(\"SELECT COUNT(*) FROM transactions\")\n",
        "    assert database.cursor.fetchone()[0] >= 5, \"Transactions not saved to DB\"\n",
        "    database.cursor.execute(\"SELECT * FROM audit_logs WHERE target_type = 'synthetic_data'\")\n",
        "    assert len(database.cursor.fetchall()) > 0, \"Audit log not recorded\"\n",
        "    database.close()\n",
        "\n",
        "def test_export_to_csv():\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(5, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    generator.export_to_csv(clients, loans, transactions)\n",
        "    assert os.path.exists(os.path.join(config.get_config()[\"data_dir\"], \"clients.csv\")), \"Clients CSV not exported\"\n",
        "    assert os.path.exists(os.path.join(config.get_config()[\"data_dir\"], \"loans.csv\")), \"Loans CSV not exported\"\n",
        "    assert os.path.exists(os.path.join(config.get_config()[\"data_dir\"], \"transactions.csv\")), \"Transactions CSV not exported\"\n",
        "''')\n",
        "!test -f tests/test_synth.py && echo \"test_synth.py created\" || echo \"Failed to create test_synth.py\"\n",
        "\n",
        "# Ensure dependencies are installed (assuming deps.py exists from previous cell)\n",
        "!python modules/bootstrap/deps.py\n",
        "\n",
        "# Verify directories\n",
        "!ls modules/synth || echo \"modules/synth not found\"\n",
        "!ls tests || echo \"tests not found\"\n",
        "!ls data || echo \"data not found\"\n",
        "\n",
        "# Run faker_engine.py\n",
        "!python modules/synth/faker_engine.py\n",
        "\n",
        "# Run generators.py\n",
        "!python modules/synth/generators.py\n",
        "\n",
        "# Run tests\n",
        "!pytest tests/test_synth.py -v\n",
        "\n",
        "# Verify files\n",
        "!ls modules/synth\n",
        "!ls tests\n",
        "!ls data\n",
        "\n",
        "# Expected output:\n",
        "# Current working directory: /content\n",
        "# Directory modules/synth created\n",
        "# Directory tests created\n",
        "# Directory data created\n",
        "# faker_engine.py created\n",
        "# generators.py created\n",
        "# test_synth.py created\n",
        "# Dependencies installed successfully.\n",
        "# faker_engine.py  generators.py\n",
        "# test_core.py  test_synth.py\n",
        "# .deps_ok  clients.csv  loans.csv  loan_iq.db  reports  transactions.csv\n",
        "# Client ID: C_...\n",
        "# Client Name: ...\n",
        "# Loan ID: L_...\n",
        "# Transaction ID: T_...\n",
        "# Income: ...\n",
        "# Branch: ...\n",
        "# Region: ...\n",
        "# Loan Amount: ...\n",
        "# Loan Status: ...\n",
        "# Transaction Amount: ...\n",
        "# Transaction Type: ...\n",
        "# Random Date: ...\n",
        "# Saving to database: data/loan_iq.db\n",
        "# Saved 10 clients, ... loans, ... transactions to DB\n",
        "# Exported data to data/[clients,loans,transactions].csv\n",
        "# Generated and saved synthetic data.\n",
        "# ============================= test session starts =============================\n",
        "# tests/test_synth.py::test_faker_engine PASSED\n",
        "# tests/test_synth.py::test_generate_clients PASSED\n",
        "# tests/test_synth.py::test_generate_loans PASSED\n",
        "# tests/test_synth.py::test_generate_transactions PASSED\n",
        "# tests/test_synth.py::test_save_to_db PASSED\n",
        "# tests/test_synth.py::test_export_to_csv PASSED\n",
        "# =========================== 6 passed in 0.XXs ==========================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8AdXBGc1g8U",
        "outputId": "dcadeb69-66bb-48d5-b5b8-bb105b8f3089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "faker_engine.py  generators.py\t__pycache__\n",
            "__pycache__  test_core.py  test_synth.py\n",
            "reports\n",
            "faker_engine.py created\n",
            "generators.py created\n",
            "test_synth.py created\n",
            "Dependencies already installed.\n",
            "faker_engine.py  generators.py\t__pycache__\n",
            "__pycache__  test_core.py  test_synth.py\n",
            "reports\n",
            "Client ID: C_bdd640fb\n",
            "Client Name: Daniel Doyle\n",
            "Loan ID: L_8b9d2434\n",
            "Transaction ID: T_0822e8f3\n",
            "Income: 71154.1438766307\n",
            "Branch: North Jefferyhaven\n",
            "Region: urban\n",
            "Loan Amount: 37335.97448823181\n",
            "Loan Status: active\n",
            "Transaction Amount: 300.88966433394046\n",
            "Transaction Type: interest\n",
            "Random Date: 2025-04-07T05:38:09.639320\n",
            "sys.path: ['/content/modules/synth', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Saving to database: data/loan_iq.db\n",
            "Saved 10 clients, 15 loans, 30 transactions to DB\n",
            "Exported data to data/[clients,loans,transactions].csv\n",
            "Generated and saved synthetic data.\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: Faker-28.1.0, anyio-4.10.0, typeguard-4.4.4, langsmith-0.4.16\n",
            "collected 6 items                                                              \u001b[0m\n",
            "\n",
            "tests/test_synth.py::test_faker_engine \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 16%]\u001b[0m\n",
            "tests/test_synth.py::test_generate_clients \u001b[32mPASSED\u001b[0m\u001b[32m                        [ 33%]\u001b[0m\n",
            "tests/test_synth.py::test_generate_loans \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 50%]\u001b[0m\n",
            "tests/test_synth.py::test_generate_transactions \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 66%]\u001b[0m\n",
            "tests/test_synth.py::test_save_to_db \u001b[32mPASSED\u001b[0m\u001b[32m                              [ 83%]\u001b[0m\n",
            "tests/test_synth.py::test_export_to_csv \u001b[32mPASSED\u001b[0m\u001b[32m                           [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 1.08s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
            "faker_engine.py  generators.py\t__pycache__\n",
            "__pycache__  test_core.py  test_synth.py\n",
            "clients.csv  loan_iq.db  loans.csv  reports  transactions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.makedirs('modules/bootstrap', exist_ok=True)\n",
        "with open('modules/bootstrap/deps.py', 'w') as f:\n",
        "    f.write('''# modules/bootstrap/deps.py\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "REQUIRED_LIBS = [\n",
        "    'streamlit==1.38.0',\n",
        "    'pandas==2.2.2',\n",
        "    'numpy==1.26.4',\n",
        "    'scikit-learn==1.5.1',\n",
        "    'xgboost==2.1.1',\n",
        "    'plotly==5.22.0',\n",
        "    'faker==28.1.0',\n",
        "    'openpyxl==3.1.5',\n",
        "    'reportlab==4.2.2',\n",
        "    'pytest==8.3.2',\n",
        "    'shap==0.46.0'\n",
        "]\n",
        "\n",
        "def install_deps():\n",
        "    \"\"\"Install required libraries and create marker file.\"\"\"\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    marker_path = os.path.join('data', '.deps_ok')\n",
        "    if not os.path.exists(marker_path):\n",
        "        for lib in REQUIRED_LIBS:\n",
        "            try:\n",
        "                __import__(lib.split('==')[0])\n",
        "            except ImportError:\n",
        "                subprocess.check_call(['pip', 'install', lib])\n",
        "        with open(marker_path, 'w') as f:\n",
        "            f.write('OK')\n",
        "        print(\"Dependencies installed successfully.\")\n",
        "    else:\n",
        "        print(\"Dependencies already installed.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    install_deps()\n",
        "''')\n",
        "!test -f modules/bootstrap/deps.py && echo \"deps.py created\" || echo \"Failed to create deps.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2V4dfVbVx4a",
        "outputId": "96381521-4fee-40e7-8204-71446de4e647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deps.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('modules/core', exist_ok=True)\n",
        "with open('modules/core/config.py', 'w') as f:\n",
        "    f.write('''# modules/core/config.py\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "ADMIN_CREDENTIALS = {\n",
        "    \"username\": \"admin\",\n",
        "    \"password\": \"Shady868\"\n",
        "}\n",
        "\n",
        "SEEDS = {\n",
        "    \"faker\": 42,\n",
        "    \"numpy\": 42,\n",
        "    \"random\": 42\n",
        "}\n",
        "\n",
        "CONFIG = {\n",
        "    \"data_dir\": os.path.join(\"data\"),\n",
        "    \"model_dir\": os.path.join(\"models\"),\n",
        "    \"report_dir\": os.path.join(\"data\", \"reports\"),\n",
        "    \"db_path\": os.path.join(\"data\", \"loan_iq.db\"),\n",
        "    \"drive_root\": \"/content/drive/MyDrive/loan_iq\",\n",
        "    \"streamlit_port\": 8501,\n",
        "    \"fraud_types\": [\"ghost_client\", \"duplicate_id\", \"missed_payment\", \"identity_theft\"],\n",
        "    \"regions\": [\"urban\", \"rural\", \"semi_urban\"],\n",
        "    \"max_clients_batch\": 70000,\n",
        "    \"default_batch_size\": 1000\n",
        "}\n",
        "\n",
        "def init_seeds():\n",
        "    \"\"\"Initialize random seeds for reproducibility.\"\"\"\n",
        "    random.seed(SEEDS[\"random\"])\n",
        "    np.random.seed(SEEDS[\"numpy\"])\n",
        "\n",
        "def get_config():\n",
        "    \"\"\"Return config dictionary, ensure directories exist.\"\"\"\n",
        "    os.makedirs(CONFIG[\"data_dir\"], exist_ok=True)\n",
        "    os.makedirs(CONFIG[\"model_dir\"], exist_ok=True)\n",
        "    os.makedirs(CONFIG[\"report_dir\"], exist_ok=True)\n",
        "    return CONFIG\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    init_seeds()\n",
        "    config = get_config()\n",
        "    print(f\"Config loaded: {config}\")\n",
        "''')\n",
        "!test -f modules/core/config.py && echo \"config.py created\" || echo \"Failed to create config.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHryHIa6V4BL",
        "outputId": "0b7e6917-d05b-4126-9fd4-b8739c32d448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('modules/core', exist_ok=True)\n",
        "with open('modules/core/db.py', 'w') as f:\n",
        "    f.write('''# modules/core/db.py\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "import sqlite3\n",
        "import json\n",
        "from datetime import datetime, UTC\n",
        "try:\n",
        "    from modules.core import config\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class DB:\n",
        "    \"\"\"SQLite database wrapper for Loan IQ.\"\"\"\n",
        "    def __init__(self):\n",
        "        print(f\"sys.path: {sys.path}\")  # Debug\n",
        "        self.db_path = config.get_config()[\"db_path\"]\n",
        "        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n",
        "        print(f\"Creating database at: {self.db_path}\")  # Debug\n",
        "        self.conn = sqlite3.connect(self.db_path)\n",
        "        self.conn.row_factory = sqlite3.Row\n",
        "        self.cursor = self.conn.cursor()\n",
        "        self.create_tables()\n",
        "        print(f\"Database created: {os.path.exists(self.db_path)}\")  # Debug\n",
        "\n",
        "    def create_tables(self):\n",
        "        \"\"\"Create database tables.\"\"\"\n",
        "        tables = [\n",
        "            \"CREATE TABLE IF NOT EXISTS users (user_id TEXT PRIMARY KEY, username TEXT UNIQUE, password TEXT, role TEXT)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS clients (client_id TEXT PRIMARY KEY, name TEXT, branch TEXT, region TEXT, income REAL, created_at TIMESTAMP)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS loans (loan_id TEXT PRIMARY KEY, client_id TEXT, amount REAL, status TEXT, start_date TIMESTAMP, FOREIGN KEY (client_id) REFERENCES clients(client_id))\",\n",
        "            \"CREATE TABLE IF NOT EXISTS transactions (transaction_id TEXT PRIMARY KEY, loan_id TEXT, amount REAL, date TIMESTAMP, type TEXT, FOREIGN KEY (loan_id) REFERENCES loans(loan_id))\",\n",
        "            \"CREATE TABLE IF NOT EXISTS models (model_id TEXT PRIMARY KEY, type TEXT, version TEXT, created_at TIMESTAMP)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS model_versions (version_id TEXT PRIMARY KEY, model_id TEXT, config_json TEXT, data_hash TEXT, metrics_json TEXT, commit_ref TEXT, comments TEXT, created_at TIMESTAMP, FOREIGN KEY (model_id) REFERENCES models(model_id))\",\n",
        "            \"CREATE TABLE IF NOT EXISTS audit_logs (log_id INTEGER PRIMARY KEY AUTOINCREMENT, actor_id TEXT, actor_role TEXT, action TEXT, target_id TEXT, target_type TEXT, reason TEXT, timestamp TIMESTAMP, before_snapshot TEXT, after_snapshot TEXT, reversible BOOLEAN, reversal_id INTEGER)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS simulations (sim_id TEXT PRIMARY KEY, user_id TEXT, params_json TEXT, created_at TIMESTAMP)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS reports (report_id TEXT PRIMARY KEY, type TEXT, path TEXT, created_at TIMESTAMP)\",\n",
        "            \"CREATE TABLE IF NOT EXISTS assets (asset_id TEXT PRIMARY KEY, path TEXT, type TEXT, created_at TIMESTAMP)\"\n",
        "        ]\n",
        "        for table_sql in tables:\n",
        "            self.cursor.execute(table_sql)\n",
        "        self.conn.commit()\n",
        "\n",
        "    def log_action(self, actor_id, actor_role, action, target_id, target_type, reason, before_snapshot, after_snapshot, reversible=False):\n",
        "        \"\"\"Log an admin action to audit_logs.\"\"\"\n",
        "        timestamp = datetime.now(UTC).isoformat()\n",
        "        snapshot_before = json.dumps(before_snapshot) if before_snapshot else \"\"\n",
        "        snapshot_after = json.dumps(after_snapshot) if after_snapshot else \"\"\n",
        "        self.cursor.execute(\n",
        "            \"INSERT INTO audit_logs (actor_id, actor_role, action, target_id, target_type, reason, timestamp, before_snapshot, after_snapshot, reversible) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "            (actor_id, actor_role, action, target_id, target_type, reason, timestamp, snapshot_before, snapshot_after, reversible)\n",
        "        )\n",
        "        self.conn.commit()\n",
        "        return self.cursor.lastrowid\n",
        "\n",
        "    def get_audit_trail(self, target_id=None, target_type=None):\n",
        "        \"\"\"Retrieve audit logs, optionally filtered.\"\"\"\n",
        "        query = \"SELECT * FROM audit_logs\"\n",
        "        params = []\n",
        "        if target_id and target_type:\n",
        "            query += \" WHERE target_id = ? AND target_type = ?\"\n",
        "            params = [target_id, target_type]\n",
        "        self.cursor.execute(query, params)\n",
        "        return self.cursor.fetchall()\n",
        "\n",
        "    def rollback_action(self, action_id):\n",
        "        \"\"\"Attempt to rollback an action if reversible.\"\"\"\n",
        "        self.cursor.execute(\"SELECT reversible, before_snapshot, target_id, target_type, action FROM audit_logs WHERE log_id = ?\", (action_id,))\n",
        "        result = self.cursor.fetchone()\n",
        "        if not result or not result[0]:\n",
        "            return False\n",
        "        before_snapshot = json.loads(result[1]) if result[1] else {}\n",
        "        target_id, target_type, action = result[2], result[3], result[4]\n",
        "        if target_type == \"user\" and action == \"edit\":\n",
        "            self.cursor.execute(\"UPDATE users SET username = ?, password = ?, role = ? WHERE user_id = ?\",\n",
        "                              (before_snapshot.get(\"username\"), before_snapshot.get(\"password\"), before_snapshot.get(\"role\"), target_id))\n",
        "            self.conn.commit()\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Close database connection.\"\"\"\n",
        "        self.conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    db = DB()\n",
        "    db.cursor.execute(\"INSERT OR IGNORE INTO users (user_id, username, password, role) VALUES (?, ?, ?, ?)\",\n",
        "                     (\"1\", \"admin\", \"Shady868\", \"admin\"))\n",
        "    db.conn.commit()\n",
        "    db.log_action(\"1\", \"admin\", \"init\", \"1\", \"user\", \"Initialize admin user\", {}, {\"username\": \"admin\"})\n",
        "    print(\"Database initialized.\")\n",
        "    db.close()\n",
        "''')\n",
        "!test -f modules/core/db.py && echo \"db.py created\" || echo \"Failed to create db.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBz7okUVV9Ay",
        "outputId": "7b501209-c56e-4116-de90-9f75e6bfc4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('modules/core', exist_ok=True)\n",
        "with open('modules/core/utils.py', 'w') as f:\n",
        "    f.write('''# modules/core/utils.py\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "import json\n",
        "from functools import wraps\n",
        "try:\n",
        "    from modules.core import db, config\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "def audit_wrapper(func):\n",
        "    \"\"\"Decorator to log admin actions with snapshots and reason.\"\"\"\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, actor_id, actor_role, reason, **kwargs):\n",
        "        if not reason:\n",
        "            raise ValueError(\"Reason is required for audited actions\")\n",
        "        database = db.DB()\n",
        "        target_id = kwargs.get('target_id', args[0] if args else 'unknown')\n",
        "        target_type = kwargs.get('target_type', func.__name__)\n",
        "        before_snapshot = {}\n",
        "        try:\n",
        "            if target_type in ['user', 'edit_user', 'delete_user', 'add_user']:\n",
        "                database.cursor.execute(\"SELECT * FROM users WHERE user_id = ?\", (target_id,))\n",
        "                row = database.cursor.fetchone()\n",
        "                before_snapshot = dict(row) if row else {}\n",
        "                print(f\"Before snapshot: {before_snapshot}\")  # Debug\n",
        "            filtered_kwargs = {k: v for k, v in kwargs.items() if k != 'target_type'}\n",
        "            result = func(*args, actor_id=actor_id, actor_role=actor_role, reason=reason, **filtered_kwargs)\n",
        "            after_snapshot = {}\n",
        "            if target_type in ['user', 'edit_user', 'delete_user', 'add_user']:\n",
        "                database.cursor.execute(\"SELECT * FROM users WHERE user_id = ?\", (target_id,))\n",
        "                row = database.cursor.fetchone()\n",
        "                after_snapshot = dict(row) if row else {}\n",
        "                print(f\"After snapshot: {after_snapshot}\")  # Debug\n",
        "            reversible = target_type in ['user', 'edit_user', 'add_user']\n",
        "            log_id = database.log_action(\n",
        "                actor_id, actor_role, func.__name__, target_id, target_type, reason,\n",
        "                before_snapshot, after_snapshot, reversible\n",
        "            )\n",
        "            database.close()\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            database.close()\n",
        "            raise Exception(f\"Action failed: {e}\")\n",
        "    return wrapper\n",
        "\n",
        "def dict_diff(before, after):\n",
        "    \"\"\"Compute difference between two dictionaries for audit logging.\"\"\"\n",
        "    diff = {}\n",
        "    for key in set(before.keys()) | set(after.keys()):\n",
        "        if before.get(key) != after.get(key):\n",
        "            diff[key] = {'before': before.get(key), 'after': after.get(key)}\n",
        "    return diff\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    @audit_wrapper\n",
        "    def test_action(target_id, actor_id, actor_role, reason):\n",
        "        return {\"result\": \"test\"}\n",
        "    result = test_action(\"test_id\", actor_id=\"1\", actor_role=\"admin\", reason=\"Test audit\")\n",
        "    print(f\"Test action result: {result}\")\n",
        "''')\n",
        "!test -f modules/core/utils.py && echo \"utils.py created\" || echo \"Failed to create utils.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmjziNv9WCSb",
        "outputId": "bba17447-1f30-477d-a122-ec8b09c9d7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utils.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('modules/core', exist_ok=True)\n",
        "with open('modules/core/auth.py', 'w') as f:\n",
        "    f.write('''# modules/core/auth.py\n",
        "import sys\n",
        "import os\n",
        "import sqlite3\n",
        "import uuid\n",
        "from datetime import datetime, UTC\n",
        "sys.path.append(os.getcwd())\n",
        "try:\n",
        "    from modules.core import db, config\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class Auth:\n",
        "    def __init__(self):\n",
        "        self.config = config.get_config()\n",
        "        self.db_path = self.config[\"db_path\"]\n",
        "\n",
        "    def authenticate(self, username, password):\n",
        "        database = db.DB()\n",
        "        try:\n",
        "            database.cursor.execute(\n",
        "                \"SELECT user_id, role FROM users WHERE username = ? AND password = ?\",\n",
        "                (username, password)\n",
        "            )\n",
        "            user = database.cursor.fetchone()\n",
        "            if user:\n",
        "                return {\"user_id\": user[0], \"role\": user[1]}\n",
        "            return None\n",
        "        finally:\n",
        "            database.close()\n",
        "\n",
        "    def register(self, username, password):\n",
        "        \"\"\"Register a new user with default user role.\"\"\"\n",
        "        database = db.DB()\n",
        "        try:\n",
        "            user_id = f\"U_{uuid.uuid4().hex[:8]}\"\n",
        "            database.cursor.execute(\n",
        "                \"INSERT OR IGNORE INTO users (user_id, username, password, role, created_at) VALUES (?, ?, ?, ?, ?)\",\n",
        "                (user_id, username, password, \"user\", datetime.now(UTC).isoformat())\n",
        "            )\n",
        "            database.conn.commit()\n",
        "            database.log_action(\n",
        "                \"1\", \"admin\", \"register_user\", user_id, \"user\",\n",
        "                f\"Registered new user {username}\", {}, {}\n",
        "            )\n",
        "            print(f\"Registered user: {username} with role: user\")\n",
        "            return {\"user_id\": user_id, \"role\": \"user\"}\n",
        "        except sqlite3.IntegrityError:\n",
        "            print(f\"Registration failed: Username {username} already exists\")\n",
        "            return None\n",
        "        finally:\n",
        "            database.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    database = db.DB()\n",
        "    try:\n",
        "        # Hardcode admin user\n",
        "        database.cursor.execute(\n",
        "            \"INSERT OR REPLACE INTO users (user_id, username, password, role, created_at) VALUES (?, ?, ?, ?, ?)\",\n",
        "            (\"1\", \"admin\", \"Shady868\", \"admin\", datetime.now(UTC).isoformat())\n",
        "        )\n",
        "        # Add test user\n",
        "        database.cursor.execute(\n",
        "            \"INSERT OR REPLACE INTO users (user_id, username, password, role, created_at) VALUES (?, ?, ?, ?, ?)\",\n",
        "            (\"test_1\", \"test_user\", \"test_pass\", \"user\", datetime.now(UTC).isoformat())\n",
        "        )\n",
        "        database.conn.commit()\n",
        "        database.log_action(\n",
        "            \"1\", \"admin\", \"add_user\", \"test_1\", \"user\", \"Added test user\", {}, {}\n",
        "        )\n",
        "        print(\"Added user: test_1\")\n",
        "    finally:\n",
        "        database.close()\n",
        "''')\n",
        "!test -f modules/core/auth.py && echo \"auth.py created\" || echo \"Failed to create auth.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG07al2dWGlC",
        "outputId": "6b1b76c6-9c61-48e7-c60a-babb4b5cd00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auth.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('modules/synth', exist_ok=True)\n",
        "with open('modules/synth/faker_engine.py', 'w') as f:\n",
        "    f.write('''# modules/synth/faker_engine.py\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "try:\n",
        "    from modules.core import config\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class LoanIQFaker:\n",
        "    \"\"\"Custom Faker for generating Loan IQ synthetic data with patterns.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.faker = Faker()\n",
        "        Faker.seed(config.SEEDS[\"faker\"])\n",
        "        random.seed(config.SEEDS[\"random\"])\n",
        "        self.config = config.get_config()\n",
        "        self.fraud_types = self.config[\"fraud_types\"]\n",
        "        self.regions = self.config[\"regions\"]\n",
        "\n",
        "    def client_id(self):\n",
        "        \"\"\"Generate unique client ID.\"\"\"\n",
        "        return f\"C_{self.faker.uuid4().split('-')[0]}\"\n",
        "\n",
        "    def loan_id(self):\n",
        "        \"\"\"Generate unique loan ID.\"\"\"\n",
        "        return f\"L_{self.faker.uuid4().split('-')[0]}\"\n",
        "\n",
        "    def transaction_id(self):\n",
        "        \"\"\"Generate unique transaction ID.\"\"\"\n",
        "        return f\"T_{self.faker.uuid4().split('-')[0]}\"\n",
        "\n",
        "    def client_name(self, fraud_type=None):\n",
        "        \"\"\"Generate client name, with ghost client pattern.\"\"\"\n",
        "        if fraud_type == \"ghost_client\" and random.random() < 0.1:\n",
        "            return None\n",
        "        return self.faker.name()\n",
        "\n",
        "    def duplicate_id(self, existing_ids):\n",
        "        \"\"\"Generate client ID with chance of duplication.\"\"\"\n",
        "        if random.random() < 0.05:\n",
        "            return random.choice(existing_ids) if existing_ids else self.client_id()\n",
        "        return self.client_id()\n",
        "\n",
        "    def income(self, fraud_type=None):\n",
        "        \"\"\"Generate income, with variance for patterns.\"\"\"\n",
        "        if fraud_type == \"identity_theft\" and random.random() < 0.1:\n",
        "            return random.uniform(100000, 1000000)\n",
        "        return random.uniform(20000, 100000)\n",
        "\n",
        "    def branch(self):\n",
        "        \"\"\"Generate branch name.\"\"\"\n",
        "        return self.faker.city()\n",
        "\n",
        "    def region(self):\n",
        "        \"\"\"Generate region from config.\"\"\"\n",
        "        return random.choice(self.regions)\n",
        "\n",
        "    def loan_amount(self, fraud_type=None):\n",
        "        \"\"\"Generate loan amount, with variance for patterns.\"\"\"\n",
        "        if fraud_type == \"missed_payment\" and random.random() < 0.2:\n",
        "            return random.uniform(50000, 200000)\n",
        "        return random.uniform(1000, 50000)\n",
        "\n",
        "    def loan_status(self, fraud_type=None):\n",
        "        \"\"\"Generate loan status, with pattern influence.\"\"\"\n",
        "        statuses = [\"active\", \"paid\", \"default\"]\n",
        "        if fraud_type == \"missed_payment\" and random.random() < 0.3:\n",
        "            return \"default\"\n",
        "        return random.choice(statuses)\n",
        "\n",
        "    def transaction_amount(self, loan_amount):\n",
        "        \"\"\"Generate transaction amount based on loan.\"\"\"\n",
        "        return random.uniform(100, min(loan_amount * 0.1, 5000))\n",
        "\n",
        "    def transaction_type(self, fraud_type=None):\n",
        "        \"\"\"Generate transaction type, with pattern influence.\"\"\"\n",
        "        types = [\"payment\", \"fee\", \"interest\"]\n",
        "        if fraud_type == \"identity_theft\" and random.random() < 0.1:\n",
        "            return \"suspicious_transfer\"\n",
        "        return random.choice(types)\n",
        "\n",
        "    def random_date(self, start_days=-365, end_days=0):\n",
        "        \"\"\"Generate random date within range.\"\"\"\n",
        "        start = datetime.now() + timedelta(days=start_days)\n",
        "        end = datetime.now() + timedelta(days=end_days)\n",
        "        return self.faker.date_time_between(start, end).isoformat()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    faker = LoanIQFaker()\n",
        "    print(f\"Client ID: {faker.client_id()}\")\n",
        "    print(f\"Client Name: {faker.client_name()}\")\n",
        "    print(f\"Loan ID: {faker.loan_id()}\")\n",
        "    print(f\"Transaction ID: {faker.transaction_id()}\")\n",
        "    print(f\"Income: {faker.income()}\")\n",
        "    print(f\"Branch: {faker.branch()}\")\n",
        "    print(f\"Region: {faker.region()}\")\n",
        "    print(f\"Loan Amount: {faker.loan_amount()}\")\n",
        "    print(f\"Loan Status: {faker.loan_status()}\")\n",
        "    print(f\"Transaction Amount: {faker.transaction_amount(10000)}\")\n",
        "    print(f\"Transaction Type: {faker.transaction_type()}\")\n",
        "    print(f\"Random Date: {faker.random_date()}\")\n",
        "''')\n",
        "!test -f modules/synth/faker_engine.py && echo \"faker_engine.py created\" || echo \"Failed to create faker_engine.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYQVd11FWLyK",
        "outputId": "78b09e09-4c7a-4278-8ba5-cdeb3e5ab368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faker_engine.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('modules/synth', exist_ok=True)\n",
        "with open('modules/synth/generators.py', 'w') as f:\n",
        "    f.write('''# modules/synth/generators.py\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "sys.path.append(os.getcwd())\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "try:\n",
        "    from modules.core import db, config\n",
        "    from modules.synth import faker_engine\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class DataGenerator:\n",
        "    \"\"\"Generate synthetic data for Loan IQ and store in database.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.faker = faker_engine.LoanIQFaker()\n",
        "        self.config = config.get_config()\n",
        "        self.db_path = self.config[\"db_path\"]\n",
        "\n",
        "    def generate_clients(self, n, fraud_ratio=0.1):\n",
        "        \"\"\"Generate n clients with optional patterns.\"\"\"\n",
        "        clients = []\n",
        "        existing_ids = []\n",
        "        for _ in range(n):\n",
        "            fraud_type = random.choices(\n",
        "                self.faker.fraud_types + [None],\n",
        "                weights=[fraud_ratio / len(self.faker.fraud_types)] * len(self.faker.fraud_types) + [1 - fraud_ratio],\n",
        "                k=1\n",
        "            )[0]\n",
        "            client_id = self.faker.duplicate_id(existing_ids) if fraud_type == \"duplicate_id\" else self.faker.client_id()\n",
        "            existing_ids.append(client_id)\n",
        "            clients.append({\n",
        "                \"client_id\": client_id,\n",
        "                \"name\": self.faker.client_name(fraud_type),\n",
        "                \"branch\": self.faker.branch(),\n",
        "                \"region\": self.faker.region(),\n",
        "                \"income\": self.faker.income(fraud_type),\n",
        "                \"created_at\": self.faker.random_date()\n",
        "            })\n",
        "        return pd.DataFrame(clients)\n",
        "\n",
        "    def generate_loans(self, clients, n_per_client=2, fraud_ratio=0.1):\n",
        "        \"\"\"Generate loans for given clients.\"\"\"\n",
        "        loans = []\n",
        "        for client_id in clients[\"client_id\"]:\n",
        "            fraud_type = random.choices(\n",
        "                self.faker.fraud_types + [None],\n",
        "                weights=[fraud_ratio / len(self.faker.fraud_types)] * len(self.faker.fraud_types) + [1 - fraud_ratio],\n",
        "                k=1\n",
        "            )[0]\n",
        "            for _ in range(random.randint(1, n_per_client)):\n",
        "                loans.append({\n",
        "                    \"loan_id\": self.faker.loan_id(),\n",
        "                    \"client_id\": client_id,\n",
        "                    \"amount\": self.faker.loan_amount(fraud_type),\n",
        "                    \"status\": self.faker.loan_status(fraud_type),\n",
        "                    \"start_date\": self.faker.random_date()\n",
        "                })\n",
        "        return pd.DataFrame(loans)\n",
        "\n",
        "    def generate_transactions(self, loans, n_per_loan=3, fraud_ratio=0.1):\n",
        "        \"\"\"Generate transactions for given loans.\"\"\"\n",
        "        transactions = []\n",
        "        for loan_id, loan_amount in zip(loans[\"loan_id\"], loans[\"amount\"]):\n",
        "            fraud_type = random.choices(\n",
        "                self.faker.fraud_types + [None],\n",
        "                weights=[fraud_ratio / len(self.faker.fraud_types)] * len(self.faker.fraud_types) + [1 - fraud_ratio],\n",
        "                k=1\n",
        "            )[0]\n",
        "            for _ in range(random.randint(1, n_per_loan)):\n",
        "                transactions.append({\n",
        "                    \"transaction_id\": self.faker.transaction_id(),\n",
        "                    \"loan_id\": loan_id,\n",
        "                    \"amount\": self.faker.transaction_amount(loan_amount),\n",
        "                    \"date\": self.faker.random_date(),\n",
        "                    \"type\": self.faker.transaction_type(fraud_type)\n",
        "                })\n",
        "        return pd.DataFrame(transactions)\n",
        "\n",
        "    def save_to_db(self, clients, loans, transactions, actor_id=\"1\", actor_role=\"admin\", reason=\"Synthetic data generation\"):\n",
        "        \"\"\"Save generated data to loan_iq.db with audit logging.\"\"\"\n",
        "        database = db.DB()\n",
        "        print(f\"Saving to database: {self.db_path}\")  # Debug\n",
        "        try:\n",
        "            for _, row in clients.iterrows():\n",
        "                database.cursor.execute(\n",
        "                    \"INSERT OR IGNORE INTO clients (client_id, name, branch, region, income, created_at) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "                    (row[\"client_id\"], row[\"name\"], row[\"branch\"], row[\"region\"], row[\"income\"], row[\"created_at\"])\n",
        "                )\n",
        "            for _, row in loans.iterrows():\n",
        "                database.cursor.execute(\n",
        "                    \"INSERT OR IGNORE INTO loans (loan_id, client_id, amount, status, start_date) VALUES (?, ?, ?, ?, ?)\",\n",
        "                    (row[\"loan_id\"], row[\"client_id\"], row[\"amount\"], row[\"status\"], row[\"start_date\"])\n",
        "                )\n",
        "            for _, row in transactions.iterrows():\n",
        "                database.cursor.execute(\n",
        "                    \"INSERT OR IGNORE INTO transactions (transaction_id, loan_id, amount, date, type) VALUES (?, ?, ?, ?, ?)\",\n",
        "                    (row[\"transaction_id\"], row[\"loan_id\"], row[\"amount\"], row[\"date\"], row[\"type\"])\n",
        "                )\n",
        "            database.conn.commit()\n",
        "            database.log_action(\n",
        "                actor_id, actor_role, \"generate_data\", \"multiple\", \"synthetic_data\", reason,\n",
        "                {}, {\"clients\": len(clients), \"loans\": len(loans), \"transactions\": len(transactions)}\n",
        "            )\n",
        "            print(f\"Saved {len(clients)} clients, {len(loans)} loans, {len(transactions)} transactions to DB\")\n",
        "        finally:\n",
        "            database.close()\n",
        "\n",
        "    def export_to_csv(self, clients, loans, transactions, output_dir=None):\n",
        "        \"\"\"Export data to CSV files.\"\"\"\n",
        "        output_dir = output_dir or self.config[\"data_dir\"]\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        clients.to_csv(os.path.join(output_dir, \"clients.csv\"), index=False)\n",
        "        loans.to_csv(os.path.join(output_dir, \"loans.csv\"), index=False)\n",
        "        transactions.to_csv(os.path.join(output_dir, \"transactions.csv\"), index=False)\n",
        "        print(f\"Exported data to {output_dir}/[clients,loans,transactions].csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generator = DataGenerator()\n",
        "    clients = generator.generate_clients(10, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    generator.save_to_db(clients, loans, transactions)\n",
        "    generator.export_to_csv(clients, loans, transactions)\n",
        "    print(\"Generated and saved synthetic data.\")\n",
        "''')\n",
        "!test -f modules/synth/generators.py && echo \"generators.py created\" || echo \"Failed to create generators.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBaEUs7SWTwU",
        "outputId": "4470f549-2ffc-4d37-a70d-d93cd6e15260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generators.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('modules/models', exist_ok=True)\n",
        "with open('modules/models/train.py', 'w') as f:\n",
        "    f.write('''# modules/models/train.py\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import random\n",
        "import uuid\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, UTC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "sys.path.append(os.getcwd())\n",
        "try:\n",
        "    from modules.core import db, config\n",
        "    from modules.synth import generators\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class ModelTrainer:\n",
        "    \"\"\"Train XGBoost model for default probability and loan limits.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.config = config.get_config()\n",
        "        self.db_path = self.config[\"db_path\"]\n",
        "        self.model_dir = self.config[\"model_dir\"]\n",
        "        os.makedirs(self.model_dir, exist_ok=True)\n",
        "        random.seed(config.SEEDS[\"random\"])\n",
        "        np.random.seed(config.SEEDS[\"numpy\"])\n",
        "\n",
        "    def prepare_data(self, clients, loans, transactions):\n",
        "        \"\"\"Prepare features and labels for training.\"\"\"\n",
        "        print(\"Preparing data for training\")  # Debug\n",
        "        data = loans.merge(clients, on=\"client_id\", how=\"left\")\n",
        "        # Aggregate transactions and flatten column names\n",
        "        agg_data = transactions.groupby(\"loan_id\").agg({\n",
        "            \"amount\": [\"sum\", \"count\"],\n",
        "            \"type\": lambda x: x.value_counts().index[0] if not x.empty else \"none\"\n",
        "        }).reset_index()\n",
        "        # Flatten MultiIndex by renaming columns\n",
        "        agg_data.columns = ['loan_id', 'transaction_amount_sum', 'transaction_count', 'transaction_type']\n",
        "        data = data.merge(agg_data, on=\"loan_id\", how=\"left\")\n",
        "        data = data[[\n",
        "            \"loan_id\", \"client_id\", \"amount\", \"status\", \"start_date\",\n",
        "            \"name\", \"branch\", \"region\", \"income\", \"created_at\",\n",
        "            \"transaction_amount_sum\", \"transaction_count\", \"transaction_type\"\n",
        "        ]]\n",
        "        features = [\"loan_amount\", \"income\", \"transaction_amount_sum\", \"transaction_count\"]\n",
        "        data = data.rename(columns={\"amount\": \"loan_amount\"})  # Rename for consistency\n",
        "        X = data[features].fillna(0)\n",
        "        y = data[\"status\"].apply(lambda x: 1 if x == \"default\" else 0)\n",
        "        print(f\"Prepared {X.shape[0]} samples with features: {features}\")  # Debug\n",
        "        return X, y\n",
        "\n",
        "    def train_model(self, X, y, model_id=None):\n",
        "        \"\"\"Train XGBoost model and save to file and database.\"\"\"\n",
        "        model_id = model_id or f\"M_{random.getrandbits(32):08x}\"\n",
        "        model = XGBClassifier(\n",
        "            n_estimators=100, max_depth=3, learning_rate=0.1,\n",
        "            random_state=config.SEEDS[\"random\"], eval_metric=\"auc\"\n",
        "        )\n",
        "        model.fit(X, y)\n",
        "        y_pred = model.predict_proba(X)[:, 1]\n",
        "        auc = roc_auc_score(y, y_pred)\n",
        "        accuracy = accuracy_score(y, model.predict(X))\n",
        "        model_path = os.path.join(self.model_dir, f\"{model_id}.pkl\")\n",
        "        with open(model_path, \"wb\") as f:\n",
        "            pickle.dump(model, f)\n",
        "        print(f\"Model saved to {model_path}\")  # Debug\n",
        "        database = db.DB()\n",
        "        try:\n",
        "            database.cursor.execute(\n",
        "                \"INSERT OR IGNORE INTO models (model_id, type, version, created_at) VALUES (?, ?, ?, ?)\",\n",
        "                (model_id, \"xgboost\", \"1.0\", datetime.now(UTC).isoformat())\n",
        "            )\n",
        "            database.cursor.execute(\n",
        "                \"INSERT INTO model_versions (version_id, model_id, config_json, data_hash, metrics_json, commit_ref, comments, created_at) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\",\n",
        "                (\n",
        "                    f\"V_{uuid.uuid4().hex[:8]}\", model_id,  # Unique version_id\n",
        "                    json.dumps({\"n_estimators\": 100, \"max_depth\": 3, \"learning_rate\": 0.1}),\n",
        "                    str(X.values.tobytes()),  # Use bytes of numeric data for hash\n",
        "                    json.dumps({\"auc\": float(auc), \"accuracy\": float(accuracy)}),\n",
        "                    \"initial\", \"Trained for default probability\", datetime.now(UTC).isoformat()\n",
        "                )\n",
        "            )\n",
        "            database.conn.commit()\n",
        "            database.log_action(\n",
        "                \"1\", \"admin\", \"train_model\", model_id, \"model\",\n",
        "                \"Trained model for default probability\", {}, {\"auc\": float(auc), \"accuracy\": float(accuracy)}\n",
        "            )\n",
        "            print(f\"Model {model_id} trained. AUC: {auc:.3f}, Accuracy: {accuracy:.3f}\")\n",
        "            return model_id\n",
        "        finally:\n",
        "            database.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    trainer = ModelTrainer()\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(100, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    generator.save_to_db(clients, loans, transactions)\n",
        "    X, y = trainer.prepare_data(clients, loans, transactions)\n",
        "    model_id = trainer.train_model(X, y)\n",
        "    print(f\"Trained model: {model_id}\")\n",
        "''')\n",
        "!test -f modules/models/train.py && echo \"train.py created\" || echo \"Failed to create train.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaegXJepWZ0s",
        "outputId": "72b336fb-08b3-49f2-b7c4-663690cadc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.makedirs('modules/models', exist_ok=True)\n",
        "with open('modules/models/predict.py', 'w') as f:\n",
        "    f.write('''# modules/models/predict.py\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap\n",
        "from datetime import datetime, UTC\n",
        "sys.path.append(os.getcwd())\n",
        "try:\n",
        "    from modules.core import db, config\n",
        "    from modules.models import train\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "class ModelPredictor:\n",
        "    \"\"\"Predict default probability and loan limits using trained model.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.config = config.get_config()\n",
        "        self.db_path = self.config[\"db_path\"]\n",
        "        self.model_dir = self.config[\"model_dir\"]\n",
        "        self.explainer = None\n",
        "\n",
        "    def predict(self, model_id, data):\n",
        "        \"\"\"Make predictions for given data using specified model.\"\"\"\n",
        "        model_path = os.path.join(self.model_dir, f\"{model_id}.pkl\")\n",
        "        with open(model_path, \"rb\") as f:\n",
        "            model = pickle.load(f)\n",
        "        print(f\"Loaded model: {model_id}\")  # Debug\n",
        "        trainer = train.ModelTrainer()\n",
        "        X, _ = trainer.prepare_data(data[\"clients\"], data[\"loans\"], data[\"transactions\"])\n",
        "        probs = model.predict_proba(X)[:, 1]\n",
        "        # Merge loans with clients to align incomes with loans\n",
        "        merged_data = data[\"loans\"].merge(data[\"clients\"][[\"client_id\", \"income\"]],\n",
        "                                        on=\"client_id\", how=\"left\")\n",
        "        loan_limits = merged_data[\"income\"] * 2.0 * (1 - probs)\n",
        "        explainer = shap.TreeExplainer(model)\n",
        "        shap_values = explainer.shap_values(X)\n",
        "        result = pd.DataFrame({\n",
        "            \"loan_id\": data[\"loans\"][\"loan_id\"],\n",
        "            \"default_probability\": probs,\n",
        "            \"recommended_loan_limit\": loan_limits,\n",
        "            \"shap_values\": [json.dumps(s.tolist()) for s in shap_values]\n",
        "        })\n",
        "        database = db.DB()\n",
        "        try:\n",
        "            database.log_action(\n",
        "                \"1\", \"admin\", \"predict\", model_id, \"model\",\n",
        "                \"Made predictions for loans\", {}, {\"num_predictions\": len(probs)}\n",
        "            )\n",
        "            database.conn.commit()\n",
        "            print(f\"Predictions made for {len(probs)} loans\")  # Debug\n",
        "            return result\n",
        "        finally:\n",
        "            database.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    predictor = ModelPredictor()\n",
        "    trainer = train.ModelTrainer()\n",
        "    generator = train.generators.DataGenerator()\n",
        "    clients = generator.generate_clients(10, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    generator.save_to_db(clients, loans, transactions)\n",
        "    X, y = trainer.prepare_data(clients, loans, transactions)\n",
        "    model_id = trainer.train_model(X, y)\n",
        "    predictions = predictor.predict(model_id, {\"clients\": clients, \"loans\": loans, \"transactions\": transactions})\n",
        "    print(predictions)\n",
        "''')\n",
        "!test -f modules/models/predict.py && echo \"predict.py created\" || echo \"Failed to create predict.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBzBxtaKWfK6",
        "outputId": "ca2f1415-e0df-45df-fa0c-aeb30ad71fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('tests', exist_ok=True)\n",
        "with open('tests/test_models.py', 'w') as f:\n",
        "    f.write('''# tests/test_models.py\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "sys.path.append(os.getcwd())\n",
        "try:\n",
        "    from modules.core import config, db\n",
        "    from modules.synth import generators\n",
        "    from modules.models import train, predict\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "def test_prepare_data():\n",
        "    trainer = train.ModelTrainer()\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(5, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    X, y = trainer.prepare_data(clients, loans, transactions)\n",
        "    assert X.shape[0] == len(loans), \"Incorrect number of samples\"\n",
        "    assert set(X.columns) == {\"loan_amount\", \"income\", \"transaction_amount_sum\", \"transaction_count\"}, \"Incorrect features\"\n",
        "    assert y.isin([0, 1]).all(), \"Invalid labels\"\n",
        "\n",
        "def test_train_model():\n",
        "    trainer = train.ModelTrainer()\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(10, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    generator.save_to_db(clients, loans, transactions)\n",
        "    X, y = trainer.prepare_data(clients, loans, transactions)\n",
        "    model_id = trainer.train_model(X, y)\n",
        "    assert os.path.exists(os.path.join(config.get_config()[\"model_dir\"], f\"{model_id}.pkl\")), \"Model file not saved\"\n",
        "    database = db.DB()\n",
        "    try:\n",
        "        database.cursor.execute(\"SELECT * FROM models WHERE model_id = ?\", (model_id,))\n",
        "        assert database.cursor.fetchone(), \"Model not saved to DB\"\n",
        "        database.cursor.execute(\"SELECT * FROM model_versions WHERE model_id = ?\", (model_id,))\n",
        "        assert database.cursor.fetchone(), \"Model version not saved to DB\"\n",
        "        database.cursor.execute(\"SELECT * FROM audit_logs WHERE target_type = 'model' AND action = 'train_model'\")\n",
        "        assert len(database.cursor.fetchall()) > 0, \"Audit log not recorded\"\n",
        "    finally:\n",
        "        database.close()\n",
        "\n",
        "def test_predict():\n",
        "    trainer = train.ModelTrainer()\n",
        "    predictor = predict.ModelPredictor()\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(5, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    generator.save_to_db(clients, loans, transactions)\n",
        "    X, y = trainer.prepare_data(clients, loans, transactions)\n",
        "    model_id = trainer.train_model(X, y)\n",
        "    predictions = predictor.predict(model_id, {\"clients\": clients, \"loans\": loans, \"transactions\": transactions})\n",
        "    assert len(predictions) == len(loans), \"Incorrect number of predictions\"\n",
        "    assert set(predictions.columns) == {\"loan_id\", \"default_probability\", \"recommended_loan_limit\", \"shap_values\"}, \"Incorrect prediction columns\"\n",
        "    assert (predictions[\"default_probability\"] >= 0).all() and (predictions[\"default_probability\"] <= 1).all(), \"Invalid probabilities\"\n",
        "    assert (predictions[\"recommended_loan_limit\"] >= 0).all(), \"Invalid loan limits\"\n",
        "    database = db.DB()\n",
        "    try:\n",
        "        database.cursor.execute(\"SELECT * FROM audit_logs WHERE target_type = 'model' AND action = 'predict'\")\n",
        "        assert len(database.cursor.fetchall()) > 0, \"Audit log not recorded\"\n",
        "    finally:\n",
        "        database.close()\n",
        "\n",
        "def test_model_persistence():\n",
        "    trainer = train.ModelTrainer()\n",
        "    generator = generators.DataGenerator()\n",
        "    clients = generator.generate_clients(5, fraud_ratio=0.2)\n",
        "    loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "    transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "    X, y = trainer.prepare_data(clients, loans, transactions)\n",
        "    model_id = trainer.train_model(X, y)\n",
        "    model_path = os.path.join(config.get_config()[\"model_dir\"], f\"{model_id}.pkl\")\n",
        "    with open(model_path, \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "    assert model is not None, \"Model not loaded correctly\"\n",
        "''')\n",
        "!test -f tests/test_models.py && echo \"test_models.py created\" || echo \"Failed to create test_models.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj5rOQxbWurA",
        "outputId": "a3c6b9c5-8904-4097-8930-902f299c08ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_models.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "print(f\"Current working directory: {os.getcwd()}\")  # Debug\n",
        "\n",
        "# Reset database and marker file\n",
        "!rm -f data/loan_iq.db data/.deps_ok\n",
        "\n",
        "# Ensure dependencies are installed\n",
        "!python modules/bootstrap/deps.py\n",
        "\n",
        "# Verify directories\n",
        "!ls modules/bootstrap || echo \"modules/bootstrap not found\"\n",
        "!ls modules/core || echo \"modules/core not found\"\n",
        "!ls modules/synth || echo \"modules/synth not found\"\n",
        "!ls modules/models || echo \"modules/models not found\"\n",
        "!ls tests || echo \"tests not found\"\n",
        "!ls data || echo \"data not found\"\n",
        "\n",
        "# Run all scripts\n",
        "!python modules/core/config.py\n",
        "!python modules/core/db.py\n",
        "!python modules/core/utils.py\n",
        "!python modules/core/auth.py\n",
        "!python modules/synth/faker_engine.py\n",
        "!python modules/synth/generators.py\n",
        "!python modules/models/train.py\n",
        "!python modules/models/predict.py\n",
        "\n",
        "# Run tests\n",
        "!pytest tests/test_models.py -v\n",
        "\n",
        "# Verify files\n",
        "!ls modules/bootstrap\n",
        "!ls modules/core\n",
        "!ls modules/synth\n",
        "!ls modules/models\n",
        "!ls tests\n",
        "!ls data\n",
        "\n",
        "# Expected output:\n",
        "# Current working directory: /content\n",
        "# Dependencies installed successfully.\n",
        "# deps.py\n",
        "# auth.py  config.py  db.py  utils.py\n",
        "# faker_engine.py  generators.py\n",
        "# predict.py  train.py\n",
        "# test_models.py\n",
        "# .deps_ok  clients.csv  loans.csv  loan_iq.db  models  reports  transactions.csv\n",
        "# Config loaded: {...}\n",
        "# sys.path: [...]\n",
        "# Creating database at: data/loan_iq.db\n",
        "# Database created: True\n",
        "# Database initialized.\n",
        "# Before snapshot: {}\n",
        "# After snapshot: {}\n",
        "# Test action result: {'result': 'test'}\n",
        "# Auth result: {'user_id': '1', 'role': 'admin'}\n",
        "# Adding user with target_id: test_1\n",
        "# Before snapshot: {}\n",
        "# After snapshot: {'user_id': 'test_1', 'username': 'test_user', 'password': 'test_pass', 'role': 'user'}\n",
        "# Added user: test_1\n",
        "# Client ID: C_...\n",
        "# Client Name: ...\n",
        "# Loan ID: L_...\n",
        "# Transaction ID: T_...\n",
        "# Income: ...\n",
        "# Branch: ...\n",
        "# Region: ...\n",
        "# Loan Amount: ...\n",
        "# Loan Status: ...\n",
        "# Transaction Amount: ...\n",
        "# Transaction Type: ...\n",
        "# Random Date: ...\n",
        "# Saving to database: data/loan_iq.db\n",
        "# Saved 10 clients, ... loans, ... transactions to DB\n",
        "# Exported data to data/[clients,loans,transactions].csv\n",
        "# Generated and saved synthetic data.\n",
        "# Saving to database: data/loan_iq.db\n",
        "# Saved 100 clients, ... loans, ... transactions to DB\n",
        "# Preparing data for training\n",
        "# Prepared ... samples with features: ['loan_amount', 'income', 'transaction_amount_sum', 'transaction_count']\n",
        "# Model saved to models/M_....pkl\n",
        "# Model M_... trained. AUC: 0.XXX, Accuracy: 0.XXX\n",
        "# Trained model: M_...\n",
        "# Saving to database: data/loan_iq.db\n",
        "# Saved 10 clients, ... loans, ... transactions to DB\n",
        "# Preparing data for training\n",
        "# Prepared ... samples with features: ['loan_amount', 'income', 'transaction_amount_sum', 'transaction_count']\n",
        "# Model saved to models/M_....pkl\n",
        "# Model M_... trained. AUC: 0.XXX, Accuracy: 0.XXX\n",
        "# Loaded model: M_...\n",
        "# Predictions made for ... loans\n",
        "# [DataFrame with loan_id, default_probability, recommended_loan_limit, shap_values]\n",
        "# ============================= test session starts =============================\n",
        "# tests/test_models.py::test_prepare_data PASSED\n",
        "# tests/test_models.py::test_train_model PASSED\n",
        "# tests/test_models.py::test_predict PASSED\n",
        "# tests/test_models.py::test_model_persistence PASSED\n",
        "# =========================== 4 passed in 0.XXs ==========================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ybAOEyTW1mG",
        "outputId": "5c9ff585-9285-40c8-8a40-591a1cf4cc69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Requirement already satisfied: scikit-learn==1.5.1 in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.1) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.1) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.5.1) (3.6.0)\n",
            "Dependencies installed successfully.\n",
            "deps.py\n",
            "auth.py  config.py  db.py  __pycache__\tutils.py\n",
            "faker_engine.py  generators.py\t__pycache__\n",
            "predict.py  __pycache__  train.py\n",
            "__pycache__  test_models.py\n",
            "clients.csv  loans.csv\treports  transactions.csv\n",
            "Config loaded: {'data_dir': 'data', 'model_dir': 'models', 'report_dir': 'data/reports', 'db_path': 'data/loan_iq.db', 'drive_root': '/content/drive/MyDrive/loan_iq', 'streamlit_port': 8501, 'fraud_types': ['ghost_client', 'duplicate_id', 'missed_payment', 'identity_theft'], 'regions': ['urban', 'rural', 'semi_urban'], 'max_clients_batch': 70000, 'default_batch_size': 1000}\n",
            "sys.path: ['/content/modules/core', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Database initialized.\n",
            "sys.path: ['/content/modules/core', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Test action result: {'result': 'test'}\n",
            "sys.path: ['/content/modules/core', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/modules/core/auth.py\", line 59, in <module>\n",
            "    database.cursor.execute(\n",
            "sqlite3.OperationalError: table users has no column named created_at\n",
            "Client ID: C_bdd640fb\n",
            "Client Name: Daniel Doyle\n",
            "Loan ID: L_8b9d2434\n",
            "Transaction ID: T_0822e8f3\n",
            "Income: 71154.1438766307\n",
            "Branch: North Jefferyhaven\n",
            "Region: urban\n",
            "Loan Amount: 37335.97448823181\n",
            "Loan Status: active\n",
            "Transaction Amount: 300.88966433394046\n",
            "Transaction Type: interest\n",
            "Random Date: 2025-04-07T08:49:21.639320\n",
            "sys.path: ['/content/modules/synth', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Saving to database: data/loan_iq.db\n",
            "Saved 10 clients, 15 loans, 30 transactions to DB\n",
            "Exported data to data/[clients,loans,transactions].csv\n",
            "Generated and saved synthetic data.\n",
            "sys.path: ['/content/modules/models', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Saving to database: data/loan_iq.db\n",
            "Saved 100 clients, 153 loans, 316 transactions to DB\n",
            "Preparing data for training\n",
            "Prepared 156 samples with features: ['loan_amount', 'income', 'transaction_amount_sum', 'transaction_count']\n",
            "Model saved to models/M_2c33350c.pkl\n",
            "sys.path: ['/content/modules/models', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/content', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Model M_2c33350c trained. AUC: 0.993, Accuracy: 0.929\n",
            "Trained model: M_2c33350c\n",
            "sys.path: ['/content/modules/models', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/content', '/content', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Saving to database: data/loan_iq.db\n",
            "Saved 10 clients, 15 loans, 30 transactions to DB\n",
            "Preparing data for training\n",
            "Prepared 15 samples with features: ['loan_amount', 'income', 'transaction_amount_sum', 'transaction_count']\n",
            "Model saved to models/M_e64d1bcb.pkl\n",
            "sys.path: ['/content/modules/models', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/content', '/content', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Model M_e64d1bcb trained. AUC: 0.807, Accuracy: 0.867\n",
            "Loaded model: M_e64d1bcb\n",
            "Preparing data for training\n",
            "Prepared 15 samples with features: ['loan_amount', 'income', 'transaction_amount_sum', 'transaction_count']\n",
            "sys.path: ['/content/modules/models', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/content', '/content', '/content', '/content', '/content', '/content']\n",
            "Creating database at: data/loan_iq.db\n",
            "Database created: True\n",
            "Predictions made for 15 loans\n",
            "       loan_id  ...                                        shap_values\n",
            "0   L_27209bdf  ...  [-0.7254708409309387, 0.7759578227996826, 0.44...\n",
            "1   L_98ae4334  ...  [0.8137450814247131, 0.7759578227996826, -0.31...\n",
            "2   L_77d21e02  ...  [0.4874284267425537, 0.7759578227996826, -0.31...\n",
            "3   L_f143262f  ...  [0.8137450814247131, 0.7759578227996826, 0.449...\n",
            "4   L_e2817efd  ...  [0.4874284267425537, -0.735328197479248, -0.31...\n",
            "5   L_5715bd6f  ...  [0.4874284267425537, -0.735328197479248, -0.28...\n",
            "6   L_00d4af59  ...  [-0.7254708409309387, -0.735328197479248, 0.44...\n",
            "7   L_f8cda88b  ...  [-0.7254708409309387, -0.735328197479248, 0.44...\n",
            "8   L_1b3dbd5c  ...  [-0.7254708409309387, -0.735328197479248, -0.3...\n",
            "9   L_81f631d4  ...  [-0.7254708409309387, -0.735328197479248, 0.44...\n",
            "10  L_295b4715  ...  [-0.7254708409309387, 0.7759578227996826, -0.3...\n",
            "11  L_eb2263dd  ...  [0.4874284267425537, -0.735328197479248, -0.31...\n",
            "12  L_1ca35cfb  ...  [0.4874284267425537, 0.7759578227996826, -0.31...\n",
            "13  L_ce88cb2d  ...  [-0.7254708409309387, -0.735328197479248, 0.44...\n",
            "14  L_913e4de2  ...  [-0.7254708409309387, -0.735328197479248, 0.44...\n",
            "\n",
            "[15 rows x 4 columns]\n",
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.12.11, pytest-8.4.1, pluggy-1.6.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: Faker-28.1.0, anyio-4.10.0, typeguard-4.4.4, langsmith-0.4.16\n",
            "collected 4 items                                                              \u001b[0m\n",
            "\n",
            "tests/test_models.py::test_prepare_data \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 25%]\u001b[0m\n",
            "tests/test_models.py::test_train_model \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 50%]\u001b[0m\n",
            "tests/test_models.py::test_predict \u001b[32mPASSED\u001b[0m\u001b[32m                                [ 75%]\u001b[0m\n",
            "tests/test_models.py::test_model_persistence \u001b[32mPASSED\u001b[0m\u001b[32m                      [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 3.99s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
            "deps.py\n",
            "auth.py  config.py  db.py  __pycache__\tutils.py\n",
            "faker_engine.py  generators.py\t__pycache__\n",
            "predict.py  __pycache__  train.py\n",
            "__pycache__  test_models.py\n",
            "clients.csv  loan_iq.db  loans.csv  reports  transactions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.makedirs('modules/streamlit_app', exist_ok=True)\n",
        "with open('modules/streamlit_app/app.py', 'w') as f:\n",
        "    f.write('''# modules/streamlit_app/app.py\n",
        "import sys\n",
        "import os\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import plotly.express as px\n",
        "import json\n",
        "sys.path.append(os.getcwd())\n",
        "try:\n",
        "    from modules.core import config, db, auth\n",
        "    from modules.synth import generators\n",
        "    from modules.models import train, predict\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    raise\n",
        "\n",
        "st.set_page_config(page_title=\"Loan IQ Dashboard\", layout=\"wide\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Streamlit dashboard for Loan IQ.\"\"\"\n",
        "    config_data = config.get_config()\n",
        "    st.title(\"Loan IQ Dashboard\")\n",
        "\n",
        "    # Authentication\n",
        "    if \"authenticated\" not in st.session_state:\n",
        "        st.session_state.authenticated = False\n",
        "        st.session_state.user_role = None\n",
        "        st.session_state.username = None\n",
        "\n",
        "    if not st.session_state.authenticated:\n",
        "        st.subheader(\"Login or Register\")\n",
        "        # Tabs for Login and Register\n",
        "        tab1, tab2 = st.tabs([\"Login\", \"Register\"])\n",
        "\n",
        "        with tab1:\n",
        "            st.subheader(\"Login\")\n",
        "            login_username = st.text_input(\"Username\", key=\"login_username\")\n",
        "            login_password = st.text_input(\"Password\", type=\"password\", key=\"login_password\")\n",
        "            if st.button(\"Login\"):\n",
        "                authenticator = auth.Auth()  # Updated to Auth\n",
        "                user = authenticator.authenticate(login_username, login_password)\n",
        "                if user:\n",
        "                    st.session_state.authenticated = True\n",
        "                    st.session_state.user_role = user[\"role\"]\n",
        "                    st.session_state.username = login_username\n",
        "                    st.success(f\"Logged in as {login_username} ({user['role']})\")\n",
        "                    st.rerun()\n",
        "                else:\n",
        "                    st.error(\"Invalid credentials. Contact admin at admin@loaniq.com for password issues.\")\n",
        "\n",
        "        with tab2:\n",
        "            st.subheader(\"Register\")\n",
        "            reg_username = st.text_input(\"New Username\", key=\"reg_username\")\n",
        "            reg_password = st.text_input(\"New Password\", type=\"password\", key=\"reg_password\")\n",
        "            if st.button(\"Register\"):\n",
        "                authenticator = auth.Auth()  # Updated to Auth\n",
        "                user = authenticator.register(reg_username, reg_password)\n",
        "                if user:\n",
        "                    st.success(f\"Registered {reg_username}. Logging in...\")\n",
        "                    st.session_state.authenticated = True\n",
        "                    st.session_state.user_role = user[\"role\"]\n",
        "                    st.session_state.username = reg_username\n",
        "                    st.rerun()\n",
        "                else:\n",
        "                    st.error(\"Registration failed: Username already exists\")\n",
        "        return\n",
        "\n",
        "    # Sidebar for navigation\n",
        "    st.sidebar.title(f\"Welcome, {st.session_state.username}\")\n",
        "    page = st.sidebar.selectbox(\"Select Page\", [\"Data Overview\", \"Predictions\", \"Reports\"])\n",
        "\n",
        "    # Initialize database\n",
        "    database = db.DB()\n",
        "    conn = sqlite3.connect(config_data[\"db_path\"])\n",
        "\n",
        "    if page == \"Data Overview\":\n",
        "        st.subheader(\"Data Overview\")\n",
        "        # Load data\n",
        "        clients = pd.read_sql_query(\"SELECT * FROM clients LIMIT 10\", conn)\n",
        "        loans = pd.read_sql_query(\"SELECT * FROM loans LIMIT 10\", conn)\n",
        "        transactions = pd.read_sql_query(\"SELECT * FROM transactions LIMIT 10\", conn)\n",
        "\n",
        "        # Display tables\n",
        "        st.write(\"### Clients\")\n",
        "        st.dataframe(clients)\n",
        "        st.write(\"### Loans\")\n",
        "        st.dataframe(loans)\n",
        "        st.write(\"### Transactions\")\n",
        "        st.dataframe(transactions)\n",
        "\n",
        "        # Simple visualization\n",
        "        if not loans.empty:\n",
        "            fig = px.bar(loans, x=\"status\", title=\"Loan Status Distribution\")\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "    elif page == \"Predictions\":\n",
        "        st.subheader(\"Loan Default Predictions\")\n",
        "        if st.session_state.user_role == \"admin\":\n",
        "            if st.button(\"Generate New Data and Predictions\"):\n",
        "                generator = generators.DataGenerator()\n",
        "                clients = generator.generate_clients(10, fraud_ratio=0.2)\n",
        "                loans = generator.generate_loans(clients, n_per_client=2, fraud_ratio=0.2)\n",
        "                transactions = generator.generate_transactions(loans, n_per_loan=3, fraud_ratio=0.2)\n",
        "                generator.save_to_db(clients, loans, transactions)\n",
        "                trainer = train.ModelTrainer()\n",
        "                X, y = trainer.prepare_data(clients, loans, transactions)\n",
        "                model_id = trainer.train_model(X, y)\n",
        "                predictor = predict.ModelPredictor()\n",
        "                predictions = predictor.predict(model_id, {\"clients\": clients, \"loans\": loans, \"transactions\": transactions})\n",
        "                # Save predictions to session state\n",
        "                st.session_state.predictions = predictions\n",
        "                st.session_state.model_id = model_id\n",
        "                st.success(f\"Generated data and trained model {model_id}\")\n",
        "\n",
        "            # Display predictions\n",
        "            if \"predictions\" in st.session_state:\n",
        "                st.write(\"### Predictions\")\n",
        "                st.dataframe(st.session_state.predictions)\n",
        "                # Plot default probabilities\n",
        "                fig = px.histogram(st.session_state.predictions, x=\"default_probability\",\n",
        "                                 title=\"Default Probability Distribution\")\n",
        "                st.plotly_chart(fig)\n",
        "        else:\n",
        "            st.error(\"Access restricted to admin users\")\n",
        "\n",
        "    elif page == \"Reports\":\n",
        "        st.subheader(\"Reports\")\n",
        "        # Example report: Average income by region\n",
        "        query = \"\"\"\n",
        "        SELECT region, AVG(income) as avg_income\n",
        "        FROM clients\n",
        "        GROUP BY region\n",
        "        \"\"\"\n",
        "        report = pd.read_sql_query(query, conn)\n",
        "        st.write(\"### Average Income by Region\")\n",
        "        st.dataframe(report)\n",
        "        fig = px.bar(report, x=\"region\", y=\"avg_income\", title=\"Average Income by Region\")\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "!test -f modules/streamlit_app/app.py && echo \"app.py created\" || echo \"Failed to create app.py\"\n",
        "\n",
        "# Install Streamlit and ngrok\n",
        "!pip install streamlit pyngrok plotly --quiet\n",
        "\n",
        "# Run Streamlit with ngrok\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Set up ngrok with hardcoded authtoken\n",
        "!ngrok config add-authtoken 31rYvgklL0EdX9bGLvTXc313efE_2GyDFGPUNAyFgB83bikTF\n",
        "\n",
        "# Start Streamlit server\n",
        "port = 8501\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\"Streamlit app running at: {public_url}\")\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"modules/streamlit_app/app.py\", \"--server.port\", str(port)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuM_9GncbO_U",
        "outputId": "7b623dcb-efd1-4232-9974-d7029d1c5bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py created\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Streamlit app running at: https://48b61e91e587.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', 'modules/streamlit_app/a...>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}